[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GEMS-MagTIP",
    "section": "",
    "text": "GEMS-MagTIP çš„æ–‡ä»¶ï¼š https://cgrg-lab.github.io/GEMS-MagTIP/zh-TW/\nå¿«é€ŸæŒ‡å—:"
  },
  {
    "objectID": "index.html#ç°¡ä»‹",
    "href": "index.html#ç°¡ä»‹",
    "title": "GEMS-MagTIP",
    "section": "ç°¡ä»‹",
    "text": "ç°¡ä»‹\nGEMS-MagTIP æ˜¯ä¸€å€‹æ•´åˆæ¼”ç®—æ³•ï¼Œæ ¹æ“šåœ°é›»èˆ‡åœ°ç£å ´è³‡æ–™è¨ˆç®—åœ°éœ‡ç™¼ç”Ÿæ©Ÿç‡å¢åŠ çš„æ™‚é–“ï¼ˆTIP, Time of Increased Probabilityï¼‰ã€‚é€™å¥—ç³»çµ±çµåˆäº†å…ˆå‰ GEMSTIPï¼ˆåœ°é›»ç›£æ¸¬ç³»çµ±çš„TIPï¼‰èˆ‡ MagTIP çš„æ–¹æ³•å­¸ï¼Œç™¼å±•å‡ºä¸€å€‹æ”¯æŒå¤šå…ƒè³‡æ–™ä¾†æºçš„å¤šè®Šé‡æ¡†æ¶ã€‚\n\n\n\nSchematic illustration of the TIP concept\n\n\n\nç™¼å±•æ­·å²\nGEMSTIPï¼ˆåœ°é›»ç›£æ¸¬ç³»çµ±çš„TIPï¼‰å°ˆæ³¨æ–¼åœ°é›»å ´ç•°å¸¸çš„è§€æ¸¬ï¼Œé–‹å•Ÿäº†æ­¤ç³»çµ±çš„ç™¼å±•ã€‚GEMSTIP ä½¿ç”¨é æ¸¬å»ºæ¨¡ã€äºŒå…ƒåˆ†é¡ä»¥åŠçµ±è¨ˆåˆ†æä¾†è¾¨è­˜åœ°é›»è³‡æ–™ä¸­çš„åœ°éœ‡å‰å…†ã€‚ç³»çµ±é¡¯ç¤ºåœ°é›»ç•°å¸¸èˆ‡åœ°éœ‡äº‹ä»¶ä¹‹é–“æœ‰é¡¯è‘—ç›¸é—œæ€§ï¼Œä¸¦æˆåŠŸå»ºç«‹äº†åœ°éœ‡æ©Ÿç‡é æ¸¬çš„å¯è¡Œæ€§ã€‚\nåœ¨ GEMSTIP çš„åŸºç¤ä¸Šï¼ŒMagTIP æ“´å±•äº†æ¼”ç®—æ³•ä»¥ç´å…¥åœ°ç£å ´è³‡æ–™ã€‚MagTIP å¤§å¹…æå‡äº†è¨ˆç®—æ•ˆç‡ï¼Œæ”¯æŒå…¨ç£å ´èˆ‡ä¸‰åˆ†é‡ç£å ´æ•¸æ“šï¼Œä¸¦å¼•å…¥æ»¾å‹•é æ¸¬ç³»çµ±ã€‚MagTIP çš„é€²å±•ä½¿å…¶èƒ½æ•´åˆç¾ä»£èˆ‡å‚³çµ±å„€å™¨çš„è³‡æ–™ï¼Œç¢ºä¿çè²´çš„æ­·å²è¨˜éŒ„å¾—ä»¥ä¿å­˜èˆ‡åˆ©ç”¨ã€‚\n\n\n\næ²¿é©\n\n\n\n\nGEMS-MagTIPï¼šçµ±ä¸€ä¸”å¤šè®Šé‡\nç¾ä»Šçš„ GEMS-MagTIP ç³»çµ±æ•´åˆäº† GEMSTIP å’Œ MagTIP çš„åŠŸèƒ½ï¼Œå¯¦ç¾åœ°é›»èˆ‡åœ°ç£è³‡æ–™çš„åŒæ­¥ä½¿ç”¨ã€‚æ­¤å¤šè®Šé‡ç³»çµ±æ”¯æŒå¤šç¨®é¡å‹çš„åœ°é›»ç£è³‡æ–™ï¼ŒåŒ…æ‹¬ä¸‰åˆ†é‡èˆ‡å–®åˆ†é‡è¨Šè™Ÿï¼Œä¸¦ç”¨æ–¼è¨ˆç®—åœ°éœ‡ç™¼ç”Ÿæ©Ÿç‡å¢åŠ çš„æ™‚é–“ï¼ˆTIPï¼‰çš„çµ±è¨ˆæŒ‡æ¨™ï¼ˆä¾‹å¦‚ååº¦ã€å³°åº¦ã€è²»é›ªè¨Šæ¯å’Œå¤è¾²ç†µï¼‰ã€‚\nGEMS-MagTIP ç³»çµ±ä»£è¡¨äº†åœ°éœ‡å‰å…†ç ”ç©¶çš„é€²ä¸€æ­¥ç™¼å±•ã€‚å®ƒæä¾›äº†ä¸€å€‹å¼·å¤§ä¸”éˆæ´»çš„å·¥å…·ï¼Œç”¨æ–¼è­˜åˆ¥èˆ‡å¤§å‹åœ°éœ‡äº‹ä»¶ç›¸é—œçš„åœ°é›»ç£ç•°å¸¸ï¼Œä¸¦åŸºæ–¼ TIP æ¦‚å¿µå¯¦ç¾è¯åˆæ¸¬ç«™çš„åœ°éœ‡æ©Ÿç‡é æ¸¬ã€‚\n\n\n\nGeo-electric and magnetic stations in the Taiwan Geophysical Network for Seismology, TGNS.\n\n\n\n\n\n\n\n\n\n\n\nGEMS-MagTIP probability forecast (map)\n\n\n\n\n\n\n\nGEMS-MagTIP probability forecast (time-series)"
  },
  {
    "objectID": "GEMS-MagTIP-insider/docs/LatexPictures.html",
    "href": "GEMS-MagTIP-insider/docs/LatexPictures.html",
    "title": "",
    "section": "",
    "text": "Full directory\n\\documentclass[border=10pt,multi,tikz]{standalone}\n\\usepackage[edges]{forest}\n\\definecolor{folderbg}{RGB}{124,166,198}\n\\definecolor{folderborder}{RGB}{110,144,169}\n\\newlength\\Size\n\\setlength\\Size{4pt}\n\\tikzset{%\n  folder/.pic={%\n    \\filldraw [draw=folderborder, top color=folderbg!50, bottom color=folderbg] (-1.05*\\Size,0.2\\Size+5pt) rectangle ++(.75*\\Size,-0.2\\Size-5pt);\n    \\filldraw [draw=folderborder, top color=folderbg!50, bottom color=folderbg] (-1.15*\\Size,-\\Size) rectangle (1.15*\\Size,\\Size);\n  },\n  file/.pic={%\n    \\filldraw [draw=folderborder, top color=folderbg!5, bottom color=folderbg!10] (-\\Size,.4*\\Size+5pt) coordinate (a) |- (\\Size,-1.2*\\Size) coordinate (b) -- ++(0,1.6*\\Size) coordinate (c) -- ++(-5pt,5pt) coordinate (d) -- cycle (d) |- (c) ;\n  },\n}\n\\forestset{%\n  declare autowrapped toks={pic me}{},\n  pic dir tree/.style={%\n    for tree={%\n      folder,\n      font=\\ttfamily,\n      grow'=0,\n    },\n    before typesetting nodes={%\n      for tree={%\n        edge label+/.option={pic me},\n   },\n    },\n  },\n  pic me set/.code n args=2{%\n    \\forestset{%\n      #1/.style={%\n        inner xsep=2\\Size,\n        pic me={pic {#2}},\n      }\n    }\n  },\n  pic me set={directory}{folder},\n  pic me set={file}{file},\n}\n\\begin{document}\n\\begin{forest}\n  pic dir tree,\n  where level=0{}{% folder icons by default; override using file for file icons\n    directory,\n  },\n[main\n  [script\n    [MagTIP\\_2021b.m, file\n    ]\n  ]\n  [src\n    [tools\n      [plotProbability.m, file\n      ]\n    ]\n    [statind.m, file\n    ]\n    [anomalyind.m, file\n    ]\n    [..., file\n    ]\n  ]\n  [output\\_var\n    [dir\\_stat\n    ]\n    [dir\\_tsAIN\n    ]\n    [dir\\_molchan\n    ]\n    [dir\\_jointstation\n    ]\n  ]\n  [spreadsheet\n    [catalog.csv, file\n    ]\n    [station\\_location.csv, file\n    ]\n  ]\n]\n\\end{forest}\n\\end{document}\n\\documentclass[border=10pt,multi,tikz]{standalone}\n\\usepackage[edges]{forest}\n\\definecolor{folderbg}{RGB}{124,166,198}\n\\definecolor{folderborder}{RGB}{110,144,169}\n\\newlength\\Size\n\\setlength\\Size{4pt}\n\\tikzset{%\n  folder/.pic={%\n    \\filldraw [draw=folderborder, top color=folderbg!50, bottom color=folderbg] (-1.05*\\Size,0.2\\Size+5pt) rectangle ++(.75*\\Size,-0.2\\Size-5pt);\n    \\filldraw [draw=folderborder, top color=folderbg!50, bottom color=folderbg] (-1.15*\\Size,-\\Size) rectangle (1.15*\\Size,\\Size);\n  },\n  file/.pic={%\n    \\filldraw [draw=folderborder, top color=folderbg!5, bottom color=folderbg!10] (-\\Size,.4*\\Size+5pt) coordinate (a) |- (\\Size,-1.2*\\Size) coordinate (b) -- ++(0,1.6*\\Size) coordinate (c) -- ++(-5pt,5pt) coordinate (d) -- cycle (d) |- (c) ;\n  },\n}\n\\forestset{%\n  declare autowrapped toks={pic me}{},\n  pic dir tree/.style={%\n    for tree={%\n      folder,\n      font=\\ttfamily,\n      grow'=0,\n    },\n    before typesetting nodes={%\n      for tree={%\n        edge label+/.option={pic me},\n   },\n    },\n  },\n  pic me set/.code n args=2{%\n    \\forestset{%\n      #1/.style={%\n        inner xsep=2\\Size,\n        pic me={pic {#2}},\n      }\n    }\n  },\n  pic me set={directory}{folder},\n  pic me set={file}{file},\n}\n\\begin{document}\n\\begin{forest}\n  pic dir tree,\n  where level=0{}{% folder icons by default; override using file for file icons\n    directory,\n  },\n[MagTIP-2021\n  [script\n    [MagTIP\\_2021b.m, file\n    ]\n  ]\n  [src\n  ]\n  [output\\_var\n    [dir\\_stat\n    ]\n    [dir\\_tsAIN\n    ]\n    [dir\\_molchan\n    ]\n    [dir\\_jointstation\n    ]\n  ]\n  [spreadsheet\n    [catalog.csv, file\n    ]\n    [station\\_location.csv, file\n    ]\n  ]\n]\n\\end{forest}\n\\end{document}\n\\documentclass[border=5pt]{standalone}\n\\usepackage{forest}\n\\definecolor{color1}{RGB}{110,144,169}\n\\definecolor{color2}{RGB}{124,166,198}\n\\def\\Size{4pt}\n\\begin{document}\n\\begin{forest}\nfor tree={\n    font=\\sffamily,\n    text=white,\n    text width=2cm,\n    minimum height=0.75cm,\n    if level=0\n      {fill=color2}\n      {fill=color1},\n    rounded corners=4pt,\n    grow'=0,\n    child anchor=west,\n    parent anchor=south,\n    anchor=west,\n    calign=first,\n    edge={color2,rounded corners,line width=1pt},\n    edge path={\n      \\noexpand\\path [draw, \\forestoption{edge}]\n      (!u.south west) +(7.5pt,0) |- (.child anchor)\\forestoption{edge label};\n    },\n    before typesetting nodes={\n    if n=1\n        {insert before={[,phantom]}}\n        {}\n        },\n    fit=band,\n    s sep=15pt,\n    before computing xy={l=15pt},\n}\n[Folder main\n  [Folder 1\n  ]\n  [Folder 2\n    [Folder 2-1\n    ]\n    [Folder 2-2\n    ]\n  ]\n  [Folder 3\n  ]\n]\n\\end{forest}\n\\end{document}"
  },
  {
    "objectID": "GEMS-MagTIP-insider/spreadsheet/README-zhtw.html",
    "href": "GEMS-MagTIP-insider/spreadsheet/README-zhtw.html",
    "title": "",
    "section": "",
    "text": "è«‹ä¸‹è¼‰æˆ–æ›´æ–° GDMSN çš„åœ°éœ‡äº‹ä»¶ç›®éŒ„ï¼Œå…¶ä¸­è¦æ¨¡ (M_L )ï¼Œä¸¦å°‡å…¶å„²å­˜è‡³ spreadsheet/catalog.csvã€‚ æª”æ¡ˆ spreadsheet/station_location.csv ç”¨æ–¼æŒ‡å®šæ¯å€‹æ¸¬ç«™çš„ä½ç½®ï¼Œå®ƒç›´æ¥åŒ…å«åœ¨GEMS-MagTIP-insiderçš„ç›®éŒ„ä¸‹ã€‚\n\nè¦é»ï¼š\n\næ¨™é¡Œåç¨±ï¼š\n\ncatalog.csvï¼šæ¨™é¡Œå¿…é ˆæ˜¯ â€˜timeâ€™ã€â€˜Lonâ€™ã€â€˜Latâ€™ã€â€˜Depthâ€™ å’Œ â€˜Magâ€™ã€‚\nstation_location.csvï¼šæ¨™é¡Œå¿…é ˆæ˜¯ â€˜codeâ€™ã€â€˜formatâ€™ã€â€˜Lonâ€™ å’Œ â€˜Latâ€™ã€‚\næ¬„ä½åç¨±çš„æ’åˆ—é †åºå¯ä»¥éš¨æ„ï¼Œä½†åç¨±å­—ä¸²å¿…é ˆå®Œå…¨ä¸€è‡´ã€‚\n\næ›´æ–°åœ°éœ‡ç›®éŒ„ï¼š\n\nè¦æ›´æ–°åœ°éœ‡ç›®éŒ„ï¼Œå°‡æ›´æ–°çš„è¡¨æ ¼ä»¥ CSV æ ¼å¼å„²å­˜è‡³ spreadsheet/catalog.csvï¼Œä¸¦å•Ÿç”¨è¦†å¯«ã€‚\nåŸ·è¡Œ checkcatalog(dir_catalog) ä¾†è™•ç†æ–°çš„ç›®éŒ„ã€‚\nå¦‚æœ dir_catalog è³‡æ–™å¤¾ä¸­åŒæ™‚å­˜åœ¨ catalog.mat å’Œ catalog.csvï¼Œå‰‡å°‡ä½¿ç”¨æ›´æ–°çš„ catalog.csv è³‡æ–™è¦†å¯«ç”Ÿæˆ catalog.matã€‚\n\næ›´æ–°æ¸¬ç«™ä½ç½®ï¼š\n\nå°‡æ›´æ–°çš„æ¸¬ç«™ä½ç½®è¡¨æ ¼å„²å­˜è‡³ spreadsheet/station_location.csvï¼Œä¸¦å•Ÿç”¨è¦†å¯«ã€‚\néµå¾ªèˆ‡æ›´æ–°åœ°éœ‡ç›®éŒ„ç›¸åŒçš„å·¥ä½œæµç¨‹ã€‚\n\n\n\n\næ”¯æ´çš„ç›®éŒ„æ ¼å¼\n\nGDMSN æ ¼å¼\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndate\ntime\nlat\nlon\ndepth\nML\nnstn\ndmin\ngap\ntrms\nERH\nERZ\nfixed\nnph\nquality\n\n\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n\n\n\nè‡ªç”±æ ¼å¼\n\n\n\ntime\nLon\nLat\nDepth\nMag\n\n\n\n\n2020/8/10 06:41\n121.59\n23.81\n29.86\n3.41\n\n\n2020/8/10 06:29\n120.57\n22.18\n43.54\n3.02\n\n\n2020/8/10 06:14\n121.7\n22.17\n124.78\n4.13\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦"
  },
  {
    "objectID": "doc_tutorial/index.html",
    "href": "doc_tutorial/index.html",
    "title": "Tutorial",
    "section": "",
    "text": "GEMS-MagTIP ä¾è³´ä»¥ä¸‹å·¥å…·ç®±ï¼› åœ¨ MATLAB æŒ‡ä»¤åˆ—ä¸­è¼¸å…¥ license('inuse') æˆ– ver å¯ä»¥åˆ—å‡ºæ‚¨é›»è…¦ä¸Šç›®å‰å¯ç”¨çš„å·¥å…·ç®±ã€‚\nToolbox in-use:\n\nMATLAB Version 9.11 (R2021b)\nMapping Toolbox Version 5.2 (R2021b)\nParallel Computing Toolbox Version 7.5 (R2021b)\nSignal Processing Toolbox Version 8.7 (R2021b)\nStatistics and Machine Learning Toolbox Version 12.2 (R2021b)\n\n\n\n\nGEMS-MagTIP ä¾è³´æ–¼ okatsn/toolbox å’Œ CGRG-lab/GEMS-MagTIP-insiderã€‚\nåœ¨åŸ·è¡Œè…³æœ¬å‰ï¼Œæ‚¨éœ€è¦å°‡é€™äº›ä¾è³´é …åŠ å…¥ç³»çµ±çš„è·¯å¾‘è¨­å®šï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n\n\nå°‡ CGRG-lab/GEMS-MagTIP-insider è¤‡è£½åˆ°æœ¬åœ°ç£ç¢Ÿä¸­ (ä¾‹å¦‚ GEMS-MagTIP-insider)ï¼Œä¸¦å°‡å…¶å…§çš„åŸå§‹ç¢¼åŠ å…¥ç³»çµ±è·¯å¾‘ï¼š\ndir_src = 'GEMS-MagTIP-insider/src';\naddpath(genpath(dir_src));\n\n\n\nå°‡ okatsn/toolbox è¤‡è£½åˆ°ä¸»ç›®éŒ„ä¸­ (ä¾‹å¦‚ GEMS-MagTIP-insider/toolbox)ï¼Œä¸¦å°‡å…¶å…§çš„åŸå§‹ç¢¼åŠ å…¥ç³»çµ±è·¯å¾‘ï¼š\ndir_toolbox = 'GEMS-MagTIP-insider/toolbox';\naddpath(genpath(dir_toolbox));"
  },
  {
    "objectID": "doc_tutorial/index.html#requirements",
    "href": "doc_tutorial/index.html#requirements",
    "title": "Tutorial",
    "section": "",
    "text": "GEMS-MagTIP ä¾è³´ä»¥ä¸‹å·¥å…·ç®±ï¼› åœ¨ MATLAB æŒ‡ä»¤åˆ—ä¸­è¼¸å…¥ license('inuse') æˆ– ver å¯ä»¥åˆ—å‡ºæ‚¨é›»è…¦ä¸Šç›®å‰å¯ç”¨çš„å·¥å…·ç®±ã€‚\nToolbox in-use:\n\nMATLAB Version 9.11 (R2021b)\nMapping Toolbox Version 5.2 (R2021b)\nParallel Computing Toolbox Version 7.5 (R2021b)\nSignal Processing Toolbox Version 8.7 (R2021b)\nStatistics and Machine Learning Toolbox Version 12.2 (R2021b)\n\n\n\n\nGEMS-MagTIP ä¾è³´æ–¼ okatsn/toolbox å’Œ CGRG-lab/GEMS-MagTIP-insiderã€‚\nåœ¨åŸ·è¡Œè…³æœ¬å‰ï¼Œæ‚¨éœ€è¦å°‡é€™äº›ä¾è³´é …åŠ å…¥ç³»çµ±çš„è·¯å¾‘è¨­å®šï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n\n\nå°‡ CGRG-lab/GEMS-MagTIP-insider è¤‡è£½åˆ°æœ¬åœ°ç£ç¢Ÿä¸­ (ä¾‹å¦‚ GEMS-MagTIP-insider)ï¼Œä¸¦å°‡å…¶å…§çš„åŸå§‹ç¢¼åŠ å…¥ç³»çµ±è·¯å¾‘ï¼š\ndir_src = 'GEMS-MagTIP-insider/src';\naddpath(genpath(dir_src));\n\n\n\nå°‡ okatsn/toolbox è¤‡è£½åˆ°ä¸»ç›®éŒ„ä¸­ (ä¾‹å¦‚ GEMS-MagTIP-insider/toolbox)ï¼Œä¸¦å°‡å…¶å…§çš„åŸå§‹ç¢¼åŠ å…¥ç³»çµ±è·¯å¾‘ï¼š\ndir_toolbox = 'GEMS-MagTIP-insider/toolbox';\naddpath(genpath(dir_toolbox));"
  },
  {
    "objectID": "doc_tutorial/index.html#getting-started",
    "href": "doc_tutorial/index.html#getting-started",
    "title": "Tutorial",
    "section": "Getting Started",
    "text": "Getting Started\nGEMS-MagTIP çš„ä¸»è¦å‡½æ•¸ éœ€è¦ä»¥ç›®éŒ„ä¸­çš„ä¸­é–“æ•¸æ“šï¼ˆå¦‚ .mat æ–‡ä»¶ï¼‰ä½œç‚ºè¼¸å…¥åƒæ•¸ï¼Œä¸¦å°‡è¼¸å‡ºæ•¸æ“šå­˜æ”¾æ–¼æŒ‡å®šçš„ç›®éŒ„ä¸­ã€‚\nä»¥ä¸‹æ˜¯ä¸€å€‹ä¸»è¦å‡½æ•¸æ“ä½œéˆçš„ç°¡å–®ç¤ºä¾‹ï¼š\n\næº–å‚™æ•¸æ“š\næ‚¨éœ€è¦æº–å‚™/æ›´æ–°ä»¥ä¸‹æ•¸æ“šï¼š\n\nåœ°éœ‡ç›®éŒ„\næ¨™æº–æ ¼å¼çš„åœ°é›»æ•¸æ“š\næ¨™æº–æ ¼å¼çš„åœ°ç£æ•¸æ“š\n\n\nåœ°éœ‡ç›®éŒ„èˆ‡æ¸¬ç«™è³‡è¨Š\nè«‹ä¸‹è¼‰æˆ–æ›´æ–° GDMSN çš„åœ°éœ‡äº‹ä»¶ç›®éŒ„ï¼Œå…¶ä¸­è¦æ¨¡ (M_L )ï¼Œä¸¦å°‡å…¶å„²å­˜è‡³ spreadsheet/catalog.csvã€‚ æª”æ¡ˆ spreadsheet/station_location.csv ç”¨æ–¼æŒ‡å®šæ¯å€‹æ¸¬ç«™çš„ä½ç½®ï¼Œå®ƒç›´æ¥åŒ…å«åœ¨GEMS-MagTIP-insiderçš„ç›®éŒ„ä¸‹ã€‚\n\nè¦é»ï¼š\n\næ¨™é¡Œåç¨±ï¼š\n\ncatalog.csvï¼šæ¨™é¡Œå¿…é ˆæ˜¯ â€˜timeâ€™ã€â€˜Lonâ€™ã€â€˜Latâ€™ã€â€˜Depthâ€™ å’Œ â€˜Magâ€™ã€‚\nstation_location.csvï¼šæ¨™é¡Œå¿…é ˆæ˜¯ â€˜codeâ€™ã€â€˜formatâ€™ã€â€˜Lonâ€™ å’Œ â€˜Latâ€™ã€‚\næ¬„ä½åç¨±çš„æ’åˆ—é †åºå¯ä»¥éš¨æ„ï¼Œä½†åç¨±å­—ä¸²å¿…é ˆå®Œå…¨ä¸€è‡´ã€‚\n\næ›´æ–°åœ°éœ‡ç›®éŒ„ï¼š\n\nè¦æ›´æ–°åœ°éœ‡ç›®éŒ„ï¼Œå°‡æ›´æ–°çš„è¡¨æ ¼ä»¥ CSV æ ¼å¼å„²å­˜è‡³ spreadsheet/catalog.csvï¼Œä¸¦å•Ÿç”¨è¦†å¯«ã€‚\nåŸ·è¡Œ checkcatalog(dir_catalog) ä¾†è™•ç†æ–°çš„ç›®éŒ„ã€‚\nå¦‚æœ dir_catalog è³‡æ–™å¤¾ä¸­åŒæ™‚å­˜åœ¨ catalog.mat å’Œ catalog.csvï¼Œå‰‡å°‡ä½¿ç”¨æ›´æ–°çš„ catalog.csv è³‡æ–™è¦†å¯«ç”Ÿæˆ catalog.matã€‚\n\næ›´æ–°æ¸¬ç«™ä½ç½®ï¼š\n\nå°‡æ›´æ–°çš„æ¸¬ç«™ä½ç½®è¡¨æ ¼å„²å­˜è‡³ spreadsheet/station_location.csvï¼Œä¸¦å•Ÿç”¨è¦†å¯«ã€‚\néµå¾ªèˆ‡æ›´æ–°åœ°éœ‡ç›®éŒ„ç›¸åŒçš„å·¥ä½œæµç¨‹ã€‚\n\n\n\n\næ”¯æ´çš„ç›®éŒ„æ ¼å¼\n\nGDMSN æ ¼å¼\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndate\ntime\nlat\nlon\ndepth\nML\nnstn\ndmin\ngap\ntrms\nERH\nERZ\nfixed\nnph\nquality\n\n\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n\n\n\nè‡ªç”±æ ¼å¼\n\n\n\ntime\nLon\nLat\nDepth\nMag\n\n\n\n\n2020/8/10 06:41\n121.59\n23.81\n29.86\n3.41\n\n\n2020/8/10 06:29\n120.57\n22.18\n43.54\n3.02\n\n\n2020/8/10 06:14\n121.7\n22.17\n124.78\n4.13\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n\nä»¥ä¸‹ç‚º station_location.csv çš„éƒ¨åˆ†å…§å®¹ç¯„ä¾‹ï¼š\n\n\n\n\n\ncode0\ncode\nformat\ntype\nLat\nLon\nStartTime\nEndTime\n\n\n\n\nmissing\nZB\nçŸ¥æœ¬\nGM\n22.7398\n121.065\n20201006\nmissing\n\n\nmissing\nXC\næ–°åŸ\nGM\n24.0383\n121.609\n20201006\nmissing\n\n\nmissing\nSM\næ—¥æœˆæ½­\nGM\n23.881\n120.908\n20191008\nmissing\n\n\nmissing\nCN\næš¨å—\nGM\n23.9576\n120.928\n20221229\nmissing\n\n\nem3\nKUOL\néå¶º\nGE\n24.9629\n121.142\n2011-09-22\n9999-12-31\n\n\nem4\nHUAL\nè¯é™µ\nGE\n24.6745\n121.368\n2012-01-17\n9999-12-31\n\n\nem5\nTOCH\né ­åŸ\nGE\n24.8435\n121.805\n2012-02-10\n9999-12-31\n\n\nem6\nENAN\nå—æ¾³\nGE\n24.4758\n121.785\n2012-02-15\n9999-12-31\n\n\nâ‹®\nâ‹®\nâ‹®\nâ‹®\nâ‹®\nâ‹®\nâ‹®\nâ‹®\n\n\n\n\n\n\n\n\n\næ¨™æº–æ ¼å¼è³‡æ–™\nå°‡åŸå§‹æ•¸æ“šè½‰æ›ç‚ºæ¨™æº–æ ¼å¼éå¸¸é‡è¦ã€‚ æ­¤è½‰æ›éç¨‹åŒ…æ‹¬æ—¥æœŸæ™‚é–“é©—è­‰ã€å°‡åœ°é›»æ•¸æ“šæŠ•å½±ç‚ºNS-EWæ ¼å¼ã€æ ¼å¼åŒ–æ–‡ä»¶åç¨±ä»¥ä¾›ç´¢å¼•ç­‰ã€‚\nä»¥ä¸‹æ˜¯ä¸€å€‹å°‡åŸå§‹æ•¸æ“šè½‰æ›ç‚ºæ¨™æº–æ ¼å¼çš„ç°¡å–®è…³æœ¬ï¼š\ndir_gems_raw = 'data-raw/GEMSdat'; % raw GEMS data\ndir_mag_raw = 'data-raw/MAG'; % raw MAG data\ndir_data = 'data-standard'; % output directory\nconv_gemsdata(dir_gems_raw, dir_data, dir_catalog); \nconv_geomagdata(dir_mag_raw, dir_data); \n\n\n\n\n\n\nTip\n\n\n\næ‚¨å¯ä»¥è‡ªç”±æ•´ç†æ”¾ç½®æ¨™æº–æ ¼å¼è³‡æ–™çš„ dir_data ä¸­çš„æ–‡ä»¶å’Œæ–‡ä»¶å¤¾ï¼Œä¹Ÿä¸å¿…æ“”å¿ƒå°åŒä¸€åŸå§‹æ•¸æ“šé€²è¡Œå¤šæ¬¡è½‰æ›æœƒç™¼ç”ŸéŒ¯èª¤ï¼Œå› ç‚ºåœ¨ GEMS-MagTIP ä¸­æ•¸æ“šè®€å–ä¾è³´æ–¼æ¨™æº–æ ¼å¼çš„æ–‡ä»¶åï¼Œè€Œæª”æ¡ˆè½‰æ›å‡½æ•¸æœƒè‡ªå‹•è™•ç†é‡è¤‡çš„æ–‡ä»¶ã€‚\nåƒé–± standarddataname å’Œ write_dataã€‚\n\n\næœ‰é—œæ›´å¤šè³‡è¨Šï¼Œè«‹åƒé–±è®€å–åŸå§‹æ•¸æ“šä¸¦å°‡å…¶è½‰æ›ç‚ºæ¨™æº–æ ¼å¼éƒ¨åˆ†ã€‚\n\n\n\nè¨­ç½®ç›®éŒ„è·¯å¾‘\nåœ¨é‹è¡Œä»»ä½•ä¸»è¦å‡½æ•¸ä¹‹å‰ï¼Œå¿…é ˆåˆ†é…è¼¸å…¥/è¼¸å‡ºæ•¸æ“šæˆ–è®Šé‡çš„ç›®éŒ„ã€‚\nä¾‹å¦‚ï¼š\n% For windows, use backslash `\\`; for unix systems, use slash `/` in the path to directories.\ndir_catalog = 'GEMS-MagTIP-insider/spreadsheet'; \n        % directory of event catalog & station location\ndir_data = 'standard-data'; \n        % directory of geomagnetic timeseries of \"standard format\"\ndir_stat = 'var-output/StatisticIndex'; \n        % directory of statistic indices\ndir_tsAIN = 'var-output/tsAIN'; \n        % directory for storing anomaly index number (AIN)\ndir_molchan = 'var-output/Molchan'; \n        % directory for storing Molchan scores\ndir_jointstation = 'var-output/JointStation'; \n        % directory for the time series of EQK, TIP and probability\n\n\n\n\n\n\nTip\n\n\n\n\næ‚¨å¯ä»¥ä½¿ç”¨ mkdir_default è‡ªå‹•ç”Ÿæˆä¸»è¦å‡½æ•¸æ‰€éœ€çš„ç©ºç›®éŒ„ã€‚\næ‚¨å¯ä»¥ä½¿ç”¨ dirselectassign é€šéæ–‡ä»¶ç€è¦½å™¨ç•Œé¢åˆ†é…ç›®éŒ„ã€‚\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\ndir_catalog å¿…é ˆåŒ…å« catalog.csv æˆ– catalog.matï¼Œä»¥åŠ station_location.csv æˆ– station_location.matã€‚\ndir_data æ˜¯åŒ…å« GE æˆ– GM æ¨™æº–æ ¼å¼è³‡æ–™çš„ç›®éŒ„ï¼›è«‹åƒé–± conv_geomagdata å’Œ conv_gemsdata ä»¥å°‡åŸå§‹æ•¸æ“šè½‰æ›ç‚ºæ¨™æº–æ ¼å¼ã€‚\n\n\n\n\n\næŒ‰æ­£ç¢ºçš„é †åºåŸ·è¡Œä¸»è¦å‡½æ•¸\nstatind(dir_data,dir_stat); \n\nanomalyind(dir_stat,dir_tsAIN); \n\nmolscore(dir_tsAIN,dir_catalog,dir_molchan); \n\nmolscore3(dir_tsAIN,dir_molchan,dir_catalog,dir_jointstation); \n\n\n\n\n\n\nTip\n\n\n\nstatindã€molscore å’Œ molscore3 æœ‰å¹³è¡Œè¨ˆç®—çš„æ›¿ä»£æ–¹æ¡ˆã€‚ åœ¨å¤§å¤šæ•¸æƒ…æ³ä¸‹ï¼Œæ‚¨åªéœ€åœ¨å‡½æ•¸åç¨±å¾Œé™„åŠ  _parfor (ä¾‹å¦‚ï¼Œmolscore3_parfor(...)) å³å¯åœ¨ä¸ä¿®æ”¹è¼¸å…¥åƒæ•¸çš„æƒ…æ³ä¸‹é€²è¡Œå¹³è¡Œé‹è¡Œã€‚ åƒé–± statind_parforã€molscore_parfor å’Œ molscore3_parforã€‚\n\n\n\n\nç¶œåˆç¯„ä¾‹è…³æœ¬\nä»¥ä¸‹æ˜¯æ•´å€‹æµç¨‹çš„ç¯„ä¾‹è…³æœ¬ â€œdemo/demo_script.mâ€ã€‚\n\n\n\n\n\n\nTip\n\n\n\næ‚¨å¯ä»¥é‹è¡Œ startup0.m ä¸¦æŒ‰ç…§å‘½ä»¤è¦–çª—ä¸­çš„æŒ‡ç¤ºï¼Œæ·»åŠ ä¾è³´é …ä¸¦åˆ†é…å¦‚ä¸Šæ‰€è¿°çš„è¼¸å…¥/è¼¸å‡ºç›®éŒ„ã€‚\n\n\n%% GEMS-MagTIP 2024\n% Follow the instruction to complete the settings. They are written in startup.m \n%% Convert Raw data to standard type\n% Load original data and save them as matfiles of the standard format\n\nconv_gemsdata(dir_data0gems, dir_data, dir_catalog,'FilterByDatetime',datetime(2020,1,1)); % Convert raw GE data of timestamps after 2020 to standard format. Use FilterByDatetime when standard geomagnetic data out of the specified date-time range already exist.\nconv_geomagdata(dir_data0mag, dir_data,'FilterByDatetime',datetime(2020,1,1)); % The same as above but for the conversion of GM data.\n\n%% Calculate Statistic Index\nstatind_parfor(dir_data,dir_stat, ... % Load data in dir_data, save index in dir_stat\n    'Preprocess',{'ULF_A','ULF_B','BP_40','BP_35'}, ... % with 4 kinds of filtering\n    'SavePreprocessedData',false, ... % without saving filtered timeseries\n    'StatName', {'S', 'K', 'FI', 'SE'},  ...\n    'StatFunction', {@skewness, @kurtosis, @fisherinformation, @shannonentropy}, ...\n    'FilterByDatetime',[datetime(2011,1,1), datetime(2022,12,31)]); % This means only statistical indices between 2011 and the end of 2022 will be calculated. Noted that standard format GE/GM data have to be available in this range, otherwise you will get NaN if data is missing (or not converted) in `dir_data`.\n\n\n%% Data overview\n% An overview of data avaliability/deficiency according to the results in dir_stat \nplot_dataoverview(dir_stat, dir_catalog);\n\n%% Calculate Anomaly Indices\nanomalyind(dir_stat,dir_tsAIN);\n\n%% Training\nmolscore_parfor(dir_tsAIN,dir_catalog,dir_molchan,... \n    'TrainingPhase', {calyears(3),datetime(2022,4,1);...\n                      calyears(5),datetime(2022,4,1);...\n                      calyears(7),datetime(2022,4,1);...\n                      calyears(9),datetime(2022,4,1)},...\n    'modparam',{'Test', 5000}); % Remember to disable 'Test' in a real run.\n\n%% Forecast and test\nmolscore3_parfor(dir_tsAIN,dir_molchan,dir_catalog,dir_jointstation,...\n    'OverwriteFile',true, ...\n    'ForecastingPhase', repmat([datetime(2022,4,2), datetime(2022,9,27)], 4,1));\n    % Manually assign forecasting phases."
  },
  {
    "objectID": "doc_tutorial/index.html#çµæœå¯è¦–åŒ–",
    "href": "doc_tutorial/index.html#çµæœå¯è¦–åŒ–",
    "title": "Tutorial",
    "section": "çµæœå¯è¦–åŒ–",
    "text": "çµæœå¯è¦–åŒ–\nSee also: Plotting functions\n\nç¹ªè£½EQK-TIP åŒ¹é…åœ–\nç¹ªè£½æ¯å€‹æ¸¬ç«™çš„ EQK-TIP åŒ¹é…åœ–ï¼š\n%% Plot EQK-TIP of each station\n\n% the output directory for the images\ndir_png = fullfile(dir_molchan,'png','EQKTIP'); % no need to mkdir\n\n% Plot TIP of individual stations as heatmap, \n% with target earthquakes (EQK) scattered on the top.\nplotEQKTIP1(dir_tsAIN,dir_molchan,dir_catalog,dir_png); %,...\n    'ForecastingPhase',calyears(1),'ShowTrainingPhase',1,'Rank',1,...\n    'ForceMagnitude',false, ...\n    'scatter',1); \n\n% remove the white space around the image.\ncropimg(dir_png,'SaveInplace',true);\n\n\n\nAn example of EQK-TIP plot.\n\n\n\nåœ¨æ­¤åœ–ä¸­ï¼Œå±•ç¤ºäº†ç”±å„æ¸¬ç«™æœ€ä½³æ¨¡å‹(rank 1)å®šç¾©çš„EQKèˆ‡TIPçš„åŒ¹é…åœ–ã€‚é»‘è‰²é–“éš”è¡¨ç¤ºåœ¨é€™äº›æ—¥æœŸä¸­ \\(T_\\text{obs}\\) å®Œå…¨æ²’æœ‰è³‡æ–™ï¼ˆå³æ­¤æ¨¡å‹åœ¨é€™äº›æ™‚é–“é»ç„¡è³‡æ–™å¯ä¾›è¨ˆç®—ï¼‰ï¼Œå› æ­¤ç„¡æ³•è¨ˆç®—TIPã€‚\n\n\n\nç¹ªè£½äºŒç¶­ EQK-TIP åŒ¹é…åœ–\nEQK-TIP åœ¨ 2D æ™‚é–“-ç©ºé–“åº§æ¨™ç³»çµ±ä¸­çš„è¡¨ç¤º\n%% EQK-TIP in a 2D temporal-spatial coordinate system\n\ndir_png = fullfile(dir_jointstation,'png', 'EQKTIP3'); mkdir(dir_png);\n\n% Find the data of ID 'AMn6ei' and filter tag 'ULF_A'\n\njid = 'AMn6ei';\nfilter_tag = 'ULF_A';\n\njpathlist = datalist(sprintf('[JointStation]ID[%s]prp[%s]*.mat', jid, filter_tag), dir_jointstation).fullpath;\n\n% Retrieve essential data from '[JointStation]' files in the jpathlist:\n\n[AlarmedRate, MissingRate,xlabels, EQKs, TIP3s, TIPv3s, TIPTimes, LatLons] = ...\n    calcFittingDegree(jpathlist);\n\n% Plot EQK-TIP on a 2D temporal-spatial coordinates\n\ntitletag = sprintf('EQK-TIP (trial ID: %s; filter: %s)', jid, filter_tag)\nplotEQKTIP3(dir_png, titletag, xlabels, EQKs, TIP3s, TIPv3s,TIPTimes, LatLons);\n\n\n\nEQK-TIP plot in temporal-spatial coordinates explained.\n\n\n\n\nç¹ªè£½æ“¬åˆç¨‹åº¦\n%% Plot fitting degree\n\ndir_png = fullfile(dir_jointstation,'fitting_degree'); mkdir(dir_png);\n\nplotFittingDegree(dir_jointstation,dir_catalog,dir_png,...\n    'ConfidenceLevel',0.95);\n\n\n\n\n\nAn example of fitting degree plot.\n\n\n\n\nç¹ªè£½æ©Ÿç‡åœ–\n%% Plot probability map\n\n% the output directory for the images\ndir_prob = fullfile(dir_jointstation,'png','prob'); \n\n% specific datetime to be plotted\ndates2plot = [datetime(2020,12,1):caldays(30):datetime(2021,2,11)]';\n\n% plot GEMS-MagTIP probability map \n% (export individual image for each date)\ndir_prob2 = plotProbability(dir_jointstation,dir_catalog,dir_prob, ...\n            'TimeRange',dates2plot,...\n            'PlotEpicenter','all'); \n);\n\n\n\n\n\n\n\nAn example of probability plot. In this figure, the triangle denotes the location of station; circle(s) around each station denote the maximum and minimum range of detection (\\(R_C\\)) of the models that are responsible for calculating the TIPs; the filled color of the triangle denotes the ratio of valid models of the day; and hollow triangle denotes the station that cannot provide TIP for the day."
  },
  {
    "objectID": "GEMS-MagTIP-insider/src/preprocess/README-zhtw.html",
    "href": "GEMS-MagTIP-insider/src/preprocess/README-zhtw.html",
    "title": "",
    "section": "",
    "text": "åœ¨ GEMS-MagTIP ä¸­ï¼Œè¨Šè™Ÿè™•ç†é€šéé è™•ç†å‡½æ•¸é€²è¡Œï¼Œé€™äº›é è™•ç†å‡½æ•¸æ˜¯ä½æ–¼ src/preprocess çš„ç‰¹æ®Šå‡½æ•¸ã€‚ no å‡½æ•¸çš„åŠŸèƒ½æ˜¯å¾çµ¦å®šçš„æª”æ¡ˆè·¯å¾‘åŒ¯å…¥è³‡æ–™ï¼Œé€™æ˜¯å¿…é ˆçš„ã€‚ æ‚¨å¯ä»¥ä½¿ç”¨ prplist = prpfunctions() åˆ—å‡ºæ‰€æœ‰çš„é è™•ç†å‡½æ•¸ã€‚ æ¿¾æ³¢å‡½æ•¸ï¼ˆä¾‹å¦‚ ULF_Aã€ULF_Bï¼Œåœ¨ prplist ä¸­ï¼‰å…±ç”¨æ ¸å¿ƒå‡½æ•¸ generalfilterprocessï¼Œè©²å‡½æ•¸å°‡ loadfilters çš„è¼¸å‡ºä½œç‚ºè¼¸å…¥ã€‚\n\né è™•ç†å‡½æ•¸çš„åŠŸèƒ½æ˜¯ä»€éº¼ï¼Ÿ\n\nåŒ¯å…¥è³‡æ–™ï¼ˆå³ Mï¼‰\nåŸ·è¡Œä¸€äº›é è™•ç†ï¼ˆä¾‹å¦‚å¸¶é€šæ¿¾æ³¢ï¼‰\nå°‡è™•ç†å¾Œçš„è³‡æ–™è¼¸å‡ºç‚ºèˆ‡ M å…·æœ‰ç›¸åŒåˆ—æ•¸çš„çŸ©é™£\nåœ¨é è™•ç†å‡½æ•¸ä¸­ä½¿ç”¨ columnind ç²å–æ™‚é–“æ¬„ä½ã€æ•¸æ“šæ¬„ä½ç­‰çš„ç´¢å¼•ã€‚\n\n\n\nå¦‚ä½•å®šç¾©è‡ªè¨‚çš„é è™•ç†å‡½æ•¸èˆ‡ statind é…åˆä½¿ç”¨ï¼Œéœ€ç¬¦åˆä»¥ä¸‹è¦æ±‚ï¼š\n\nç¬¬ä¸€å€‹è¼¸å…¥åƒæ•¸æ‡‰ç‚ºæ¨™æº–æ ¼å¼æª”æ¡ˆçš„è·¯å¾‘ fpathã€‚\nå¾ fpath åŒ¯å…¥è³‡æ–™ã€‚\nç¢ºä¿æ¬„ä½ç´¢å¼•èˆ‡ columnind ç›¸å®¹ã€‚\nå°‡å‡½æ•¸çš„ .m æª”æ”¾ç½®æ–¼ src/preprocess è³‡æ–™å¤¾ä¸‹ (èˆ‡ no.m åŒä¸€å€‹è³‡æ–™å¤¾éšå±¤)ã€‚\n\n\n\nå¦‚ä½•ä½¿ç”¨\n\né€šéstatind éšæ®µçš„ 'Preprocess' æ¥å£ï¼šstatind(..., 'Preprocess', 'ULF_A') (ULF_A å¯ä»£æ›æˆ prpfunctions() æ‰€åˆ—çš„ä»»æ„å‡½æ•¸å)ã€‚\nè¦‹ä»¥ä¸‹ç¯„ä¾‹ã€‚\n\n\n\nç¯„ä¾‹\nå…§å»ºå››å€‹é è™•ç†å‡½æ•¸ï¼Œåˆ†åˆ¥ç‚º BP_35ã€BP_40ã€ULF_A å’Œ ULF_Bï¼›é€™äº›æ¿¾æ³¢å™¨å¯é€é statind éšæ®µä¸­çš„ 'Preprocess' é—œéµå­—åƒæ•¸é€²è¡Œæ‡‰ç”¨ã€‚\nä»¥ä¸‹ç¯„ä¾‹å±•ç¤ºç›´æ¥ä½¿ç”¨ï¼ˆéé€šé statind éšæ®µçš„ 'Preprocess' æ¥å£ï¼‰BP_35 çš„æ–¹æ³•ï¼š\nfpath = 'D:\\GeoMag (main)\\GeoMag_GO\\KUOL\\stn[KUOL]dt[20150714]type[GEMS].mat';\nM_out = BP_35(fpath);\nåœ¨æ­¤ç¯„ä¾‹ä¸­ï¼Œè³‡æ–™å¾ fpath åŒ¯å…¥ç‚ºè®Šæ•¸ï¼Œç„¶å¾Œèª¿ç”¨ generalfilterprocessï¼Œé»˜èªä½¿ç”¨ bandpassï¼Œæ¯æ¬¡åŒ¯å…¥è³‡æ–™æ™‚å‰µå»ºä¸€å€‹å¸¶é€šæ¿¾æ³¢å™¨ï¼Œä¸¦å°‡æ¿¾æ³¢å¾Œçš„è³‡æ–™è¼¸å‡ºç‚ºèˆ‡ M å…·æœ‰å®Œå…¨ç›¸åŒæ¬„ä½(ç›´è¡Œ)æ•¸çš„ M_outï¼ˆä½†æ©«åˆ—æ•¸å¯èƒ½æœ‰æ‰€æ¸›å°‘ï¼‰ã€‚\nå¦ä¸€å€‹ç¯„ä¾‹å‰‡æ˜¯æ‡‰ç”¨ç¾æœ‰çš„æ¿¾æ³¢å™¨ï¼ˆä¾‹å¦‚ 'Filter[BP_35]samp[1]stp[093].mat'ï¼‰æ–¼ dir_filter ä¸­ï¼ˆå¦‚æœå¯èƒ½ï¼‰ï¼š\nfpath = 'D:\\GeoMag (main)\\GeoMag_GO\\KUOL\\stn[KUOL]dt[20150714]type[GEMS].mat';\nfiltpaths = datalist('Filter*.mat', dir_filter);\nFOBJ = loadfilters(filtpaths); % load all filters as a struct FOBJ\nM_out = BP_35(fpath, FOBJ);"
  },
  {
    "objectID": "GEMS-MagTIP-insider/filter_temp/brief_report.html#summary",
    "href": "GEMS-MagTIP-insider/filter_temp/brief_report.html#summary",
    "title": "",
    "section": "Summary",
    "text": "Summary\n\nwhen sampling frequency is 50Hz, filters mostly failed on almost all analysis.\n\n\ngreen\n\n\n\n\n\n\n\n\n\n\n\n\n\nLN, fs=1\nHERM, fs=15\nKUOL, fs=15\nKUOL, fs=50\nENAN, fs=15\n\n\n\n\n0.93\nBP_35\nâœ”ï¸\nâŒ\nâŒ\nâŒ\nâŒ\n\n\n\nBP_40\nâœ”ï¸\nâœ”ï¸\nâŒ\nâŒ\nâœ”ï¸\n\n\n\nULF_A\nâœ”ï¸\nâœ”ï¸\nâŒ\nâŒ\nâœ”ï¸\n\n\n\nULF_B\nâœ”ï¸\nâœ”ï¸\nâœ”ï¸\nğŸ”º\nâœ”ï¸\n\n\n0.95\nBP_35\nâœ”ï¸\nâœ”ï¸\nâŒ\nâŒ\nâœ”ï¸\n\n\n\nBP_40\nâœ”ï¸\nâœ”ï¸\nâŒ\nâŒ\nâœ”ï¸\n\n\n\nULF_A\nâœ”ï¸\nâœ”ï¸\nâŒ\nâŒ\nâœ”ï¸\n\n\n\nULF_B\nâœ”ï¸\nâœ”ï¸\nâœ”ï¸\nâœ”ï¸\nâœ”ï¸\n\n\n0.98\nBP_35\nâœ”ï¸\nâŒ\nâŒ\nâŒ\nâœ”ï¸\n\n\n\nBP_40\nâœ”ï¸\nâœ”ï¸\nâŒ\nâŒ\nâœ”ï¸\n\n\n\nULF_A\nâœ”ï¸\nâœ”ï¸\nâœ”ï¸\nâŒ\nâœ”ï¸\n\n\n\nULF_B\nâœ”ï¸\nâœ”ï¸\nâœ”ï¸\nâŒ\nâœ”ï¸"
  },
  {
    "objectID": "GEMS-MagTIP-insider/filter_temp/brief_report.html#testing-code",
    "href": "GEMS-MagTIP-insider/filter_temp/brief_report.html#testing-code",
    "title": "",
    "section": "Testing code",
    "text": "Testing code\ndirselectassign('dir_sampledata');\ndlist = datalist('*.mat', dir_sampledata).fullpath;\nfor i = 1:length(dlist)\n    fpath = dlist{i};\n    autobandpassfilter(fpath, 'SaveFilter', true,'OutputDir', 'filter_temp',  'Steepness', 0.93);\nend\n\nfor i = 1:length(dlist)\n    fpath = dlist{i};\n    autobandpassfilter(fpath, 'SaveFilter', true,'OutputDir', 'filter_temp', 'Steepness', 0.95);\nend\n\nfor i = 1:length(dlist)\n    fpath = dlist{i};\n    autobandpassfilter(fpath, 'SaveFilter', true,'OutputDir', 'filter_temp', 'Steepness', 0.98);\nend"
  },
  {
    "objectID": "doc_quickguide/index.html#ç’°å¢ƒèˆ‡ç›¸ä¾å¥—ä»¶è¨­å®š",
    "href": "doc_quickguide/index.html#ç’°å¢ƒèˆ‡ç›¸ä¾å¥—ä»¶è¨­å®š",
    "title": "A Quick Guide to GEMS-MagTIP Documentation",
    "section": "ç’°å¢ƒèˆ‡ç›¸ä¾å¥—ä»¶è¨­å®š",
    "text": "ç’°å¢ƒèˆ‡ç›¸ä¾å¥—ä»¶è¨­å®š"
  },
  {
    "objectID": "doc_quickguide/index.html#è³‡æ–™æº–å‚™",
    "href": "doc_quickguide/index.html#è³‡æ–™æº–å‚™",
    "title": "A Quick Guide to GEMS-MagTIP Documentation",
    "section": "è³‡æ–™æº–å‚™",
    "text": "è³‡æ–™æº–å‚™\n\n\nåœ°éœ‡ç›®éŒ„"
  },
  {
    "objectID": "doc_quickguide/index.html#è³‡æ–™æº–å‚™-1",
    "href": "doc_quickguide/index.html#è³‡æ–™æº–å‚™-1",
    "title": "A Quick Guide to GEMS-MagTIP Documentation",
    "section": "è³‡æ–™æº–å‚™",
    "text": "è³‡æ–™æº–å‚™\n\n\nGEMS-MagTIP å°ˆæœ‰çš„æ¨™æº–æ ¼å¼è³‡æ–™\n\n\n\n\nSee also conv_geomagdata and conv_gemsdata."
  },
  {
    "objectID": "doc_quickguide/index.html#è¨­å®šè¼¸å‡ºè®Šæ•¸ç›¸ä¾è³‡æ–™å¤¾",
    "href": "doc_quickguide/index.html#è¨­å®šè¼¸å‡ºè®Šæ•¸ç›¸ä¾è³‡æ–™å¤¾",
    "title": "A Quick Guide to GEMS-MagTIP Documentation",
    "section": "è¨­å®šè¼¸å‡ºè®Šæ•¸ç›¸ä¾è³‡æ–™å¤¾",
    "text": "è¨­å®šè¼¸å‡ºè®Šæ•¸ç›¸ä¾è³‡æ–™å¤¾\n\n\n\n\n\n\nSee also: Tips on directory select and assignment."
  },
  {
    "objectID": "doc_quickguide/index.html#å®Œæ•´æµç¨‹ç¯„ä¾‹",
    "href": "doc_quickguide/index.html#å®Œæ•´æµç¨‹ç¯„ä¾‹",
    "title": "A Quick Guide to GEMS-MagTIP Documentation",
    "section": "å®Œæ•´æµç¨‹ç¯„ä¾‹",
    "text": "å®Œæ•´æµç¨‹ç¯„ä¾‹\n%% GEMS-MagTIP 2024\n% Follow the instruction to complete the settings. They are written in startup.m \n%% Convert Raw data to standard type\n% Load original data and save them as matfiles of the standard format\n\nconv_gemsdata(dir_data0gems, dir_data, dir_catalog,'FilterByDatetime',datetime(2020,1,1)); % Convert raw GE data of timestamps after 2020 to standard format. Use FilterByDatetime when standard geomagnetic data out of the specified date-time range already exist.\nconv_geomagdata(dir_data0mag, dir_data,'FilterByDatetime',datetime(2020,1,1)); % The same as above but for the conversion of GM data.\n\n%% Calculate Statistic Index\nstatind_parfor(dir_data,dir_stat, ... % Load data in dir_data, save index in dir_stat\n    'Preprocess',{'ULF_A','ULF_B','BP_40','BP_35'}, ... % with 4 kinds of filtering\n    'SavePreprocessedData',false, ... % without saving filtered timeseries\n    'StatName', {'S', 'K', 'FI', 'SE'},  ...\n    'StatFunction', {@skewness, @kurtosis, @fisherinformation, @shannonentropy}, ...\n    'FilterByDatetime',[datetime(2011,1,1), datetime(2022,12,31)]); % This means only statistical indices between 2011 and the end of 2022 will be calculated. Noted that standard format GE/GM data have to be available in this range, otherwise you will get NaN if data is missing (or not converted) in `dir_data`.\n\n\n%% Data overview\n% An overview of data avaliability/deficiency according to the results in dir_stat \nplot_dataoverview(dir_stat, dir_catalog);\n\n%% Calculate Anomaly Indices\nanomalyind(dir_stat,dir_tsAIN);\n\n%% Training\nmolscore_parfor(dir_tsAIN,dir_catalog,dir_molchan,... \n    'TrainingPhase', {calyears(3),datetime(2022,4,1);...\n                      calyears(5),datetime(2022,4,1);...\n                      calyears(7),datetime(2022,4,1);...\n                      calyears(9),datetime(2022,4,1)},...\n    'modparam',{'Test', 5000}); % Remember to disable 'Test' in a real run.\n\n%% Forecast and test\nmolscore3_parfor(dir_tsAIN,dir_molchan,dir_catalog,dir_jointstation,...\n    'OverwriteFile',true, ...\n    'ForecastingPhase', repmat([datetime(2022,4,2), datetime(2022,9,27)], 4,1));\n    % Manually assign forecasting phases.\nSee also /GEMS-MagTIP-insider/demo/demo_script.m and\n\n\n\nåŸå§‹æ•¸æ“šçš„è®€å–ä»¥åŠæ¨™æº–æ ¼å¼çš„è½‰æ›\nä¸»è¦å‡½æ•¸\n\n\n\nå¯ç”¨çš„é è™•ç†å‡½æ•¸\né—œæ–¼å¹³è¡Œé‹ç®—çš„æç¤º"
  },
  {
    "objectID": "doc_quickguide/index.html#ç¹ªè£½çµæœ",
    "href": "doc_quickguide/index.html#ç¹ªè£½çµæœ",
    "title": "A Quick Guide to GEMS-MagTIP Documentation",
    "section": "ç¹ªè£½çµæœ",
    "text": "ç¹ªè£½çµæœ\n\n\nåŒæ™‚åƒç…§ï¼šç¹ªåœ–å‡½å¼"
  },
  {
    "objectID": "doc_library/index.html",
    "href": "doc_library/index.html",
    "title": "Library",
    "section": "",
    "text": "Warning\n\n\n\n\nè«‹å‹¿å°‡æœªè¨˜éŒ„çš„åç¨±-å€¼å°åƒæ•¸åˆ†é…çµ¦å‡½æ•¸ã€‚ä¾‹å¦‚ï¼Œ'CreateInfoOnly' å’Œ 'InParforLoop'ï¼Œé€™äº›åƒæ•¸æ˜¯ç‚ºå¹³è¡Œé‹ç®—ä¿ç•™çš„ï¼Œé™¤éæ‚¨æ˜¯é–‹ç™¼è€…ï¼Œå¦å‰‡ç„¡éœ€æ‰‹å‹•è¨­ç½®å®ƒå€‘ã€‚"
  },
  {
    "objectID": "doc_library/index.html#main-functions",
    "href": "doc_library/index.html#main-functions",
    "title": "Library",
    "section": "Main Functions",
    "text": "Main Functions\nåœ¨å®Œæ•´çš„ GEMS-MagTIP å·¥ä½œæµç¨‹ä¸­ï¼Œä¸»è¦åˆ†ç‚ºå››å€‹éšæ®µï¼Œæ¯å€‹éšæ®µå°æ‡‰ä»¥ä¸‹ä¸»è¦å‡½æ•¸ï¼š\n\nstatindï¼šçµ±è¨ˆæŒ‡æ¨™çš„è¨ˆç®—ã€‚\nanomalyindï¼šåŸºæ–¼çµ±è¨ˆæŒ‡æ¨™è¨ˆç®—ç•°å¸¸æŒ‡æ¨™æ•¸å€¼ã€‚\nmolscoreï¼šåŸºæ–¼ç•°å¸¸æŒ‡æ¨™çš„è¨“ç·´éšæ®µï¼ŒåŒ…æ‹¬å–®æ¸¬ç«™ TIP çš„è¨ˆç®—ã€åŒ¹é…ç›®æ¨™åœ°éœ‡çš„ TIPï¼Œä»¥åŠè¨ˆç®— Molchan å¾—åˆ†ã€‚\nmolscore3ï¼šåŸºæ–¼æœ€é«˜ Molchan å¾—åˆ†çš„æ¨¡å‹åƒæ•¸é€²è¡Œé å ±éšæ®µï¼ŒåŒ…æ‹¬è¨ˆç®—è¯åˆæ¸¬ç«™ TIP å’ŒåŸºæ–¼ç¬¬ 2ã€3 æ­¥çµæœçš„æ©Ÿç‡ã€‚\n\né€™å››å€‹éšæ®µç”±å››å€‹å‡½æ•¸å°è£ï¼Œä¸¦æä¾›é—œéµå­—åƒæ•¸ï¼Œå…è¨±æˆ‘å€‘è‡ªè¨‚ä¸€äº›èˆ‡æ¨¡å‹å„ªåŒ–å’Œæ©Ÿç‡é å ±ç›¸é—œçš„è¶…åƒæ•¸ã€‚\n\n\n\n\n\n\nDocstring\n\n\n\n\n\n\n\n\nstatind\nstatind(dir_data,dir_output) calculate daily statistics (a statistical quantity as an index of the day) of the daily timeseries in dir_data. The output variables are stored in dir_output.\nExample:\nstatind(dir_data,dir_output,'StatName','S','StatFunction',@skewness, 'Preprocess', {'ULF_A','ULF_B'});\nIn which, dir_data is the directory for the time series in the standard format; dir_output is the dir_stat mentioned before.\nKeyword Arguments:\n\n'StatName'\n\nThe abbreviations for the name of statistical indices. They can be arbitrarily defined but have to be the same number of elements as that of 'StatFunction'.\nDefault is {'S','K'} (for Skewness and Kurtosis).\n\n'StatFunction'\n\nThe function handle for calculating statistical index.\nIt has to be of the same number of elements as that of 'StatName'\nDefault is {@skewness,@kurtosis} for calling the skewness() and kurtosis() functions.\n\n'Preprocess'\n\nApply filter(s) to time series loaded from dir_data.\nDefault is {'no'}, which applies only minimal preprocessings.\nUse prpfunctions() to list all available preprocessing functions.\nIf multiple preprocessing functions are applied, for example {'no', 'ULF_A'}, then two sets of result according to no-filter data and ULF_A band passed data are going to be produced.\n\n'FilterByDatetime'\n\nIt should be a two element datetime array.\nIf applied, all files with date time tag not in the range will be ignored.\nDefault is [datetime(0001,1,1), datetime(2999,12,31)], resulting in no data selection by date time tag.\n\n'UpdateExisting'\n\nIf true, the array size in the existing statistic indices (files starts with â€œ[StatisticIndex]â€) will be extended, and the DateTime in Information file in the dir_output will all be updated to cover the datetime of the data in dir_data. (Hint: use 'FilterByDatetime' to avoid re-calculate all data in the dir_data)\nDefault is false; that a complete new session starts with the old Info renamed.\nCurrently this option is not supported by statind_parfor.\nNoted that 'SkipExist' will be set to false if 'UpdateExisting' is true to avoid unexpected behavior (there must be something wrong that you update the array sizes of the existing files to adapt latest DateTime, but also skip the calculation of statistical indices for those files).\nNoted that 'UpdateExisting' not only extend the full date time list to the latest, but also to the earliest available data time obtained according to the data list of dir_data. Thus, you may like to apply 'FilterByDatetime' to prevent the update according to earlier pasts.\n\n'SkipExist'\n\nSet it true to skip calculations if in the current loop a file in dir_stat of the\n\nsame 'stn' and 'prp' already exists.\n\nA typical scenario to use this option is when your last calculation is not completed yet.\nDefault is false.\n\n'LoadFilters', dir_filter\n\nLoad all filters in dir_filter once for performance. See loadfilters, generalfilterprocess.\n\n\n\n\nstatind_parfor\nstatind_parfor is the parallel computing version of statind, it takes the same input arguments and keyword options as statind.\nNoted that the option 'UpdateExisting', true is not supported in statind_parfor; besides this option, all documented statind keyword arguments are supported as well as the following additional Keyword Arguments:\n\n'NumCore': Assign specific how many CPU workers to be used in the paralell pool.\nDefault is 0, that the number of CPU cores to be used for paralell computing is automatically decided.\n'ReverseDatalist': Simply reverse the list of data. This might save time when you try to continue from previous unfinished calculation with the 'SkipExist' set true. The default is false.\n\n\n\nanomalyind\nanomalyind(dir_stat,dir_output) calculates anomaly index number (AIN) according to a list of \\(A_\\text{thr}\\); dir_out is where the output variables stored.\nExample:\nanomalyind(dir_stat,dir_tsAIN);\nKeyword Arguments:\n\n'AthrList':\n\nthe list of \\(A_\\text{thr}\\) (the multiplier of the median value of the statistical indices within the moving time window)\ndefault is [1:10]\n\n'MovingWindow'\n\nthe moving-window length for calculating the median value mentioned above\ndefault is 1000 (days)\n\n\nInput and output:\n\nanomalyind takes the statistic index output from statind by loading them from dir_stat.\nThe calculated anomaly index is saved in dir_tsAIN.\n\n\n\nmolscore\nmolscore(dir_tsAIN,dir_catalog,dir_molchan) is responsible for single stationâ€™s TIP & Molchan score calculation.\nExample:\ndir_catalog = 'Workspace/GEMS-MagTIP-insider/spreadsheet';\ndir_tsAIN = 'Workspace/var-output/tsAIN-J13-TZ2';\ndir_molchan = 'Workspace/var-output/MolchanScore-J13-TZ2';\nmolscore(dir_tsAIN,dir_catalog,dir_molchan);\nKeyword Arguments:\n\nâ€˜TrainingPhaseâ€™\n\nAssigns a (set of) training phase(s). It should be of type 'calendarDuration', 'duration', an N by 2 array of 'datetime', or an N by 2 cell array, where N is the number of the training phases. If given an N by 2 array specifying N training phases, then N sets of results will be produced separately, with output format being '[MolScore]stn[%x]ID[%s]prp[%s]dt[%s-%s].mat'.\nFor example, a 4 by 2 datetime array reshape(datetime(2009:2016,2,1),[],2) specifies the start and end date of 4 training phases, with the first column being the datetime of the start and the second column being the end of each training phases.\nFor example, a 3 by 2 cell array\n{calyears(7),datetime(2012,11,11);...\n calyears(7),datetime(2011,11,11);...\n calyears(7),datetime(2010,11,11)};\nspecifies the end day of the training phases as 2010-Nov-11, 2011-Nov-11 and 2012-Nov-11, all having a length of 7-year-long training period (i.e.Â calyears(7)). If the duration is negative (e.g.Â -calyears(7)), the datetime of the second column become the first day of each training phase.\nDefault is calyears(7), which specifies the end day of training phase the day before the last day of statistical indices or anomaly index number, with a length of 7 year period. That is, in default it â€œtrainsâ€ and gives the best models according to the most recent 7-year data.\n\nâ€˜modparamâ€™\n\nSpecify the model parameters for grid search. It should be a cell array; all elements in the cell array will be directly passed into modparam() as input arguments.\nFor example, {'Athr',[1:2:10],'Rc',[20, 30]}.\nDefault is {}.\n\nâ€˜AdditionalCheckâ€™\n\nApply some additional check and tests. This option is for developer.\nDefault is false.\n\n'SkipExist'\n\nSet it true to skip calculations if there is a file in dir_output having exactly the same name already (which means, having the same filter tag, station name and training phase).\nA typical scenario to use this option is when your last calculation was aborted manually or interrupted by an error event.\nDefault is false.\n\n\nInput and output:\n\nmolscore takes anomaly indices from dir_tsAIN and earthquake catalog and station information from dir_catalog.\nThe output ranked models are saved in dir_molchan.\nIn the \"[MolchanScore]Information.mat\", Info.DateTime is inherited from \"[tsAIN]Information.mat\" (whose DateTime is inherited from \"[StatisticIndex]Information.mat\")\n\n\n\nmolscore_parfor\nmolscore_parfor is the parallel computing version of molscore, it takes the same input arguments and supports all documented keyword arguments as molscore.\n\n\nmolscore3\nmolscore3 calculates the joint-station TIP, the Molchan score between EQK and TIP, the Hit rate, and the earthquake probability. The calculation is based on optimized model given by molscore.\nExample:\ndir_catalog = 'Workspace/GEMS-MagTIP-insider/spreadsheet';\ndir_tsAIN = 'Workspace/var-output/tsAIN-J13-TZ2';\ndir_molchan = 'Workspace/var-output/MolchanScore-J13-TZ2';\ndir_jointstation = 'Workspace/var-output/JointStation-J13-TZ2';\nmolscore3(dir_tsAIN,dir_molchan,dir_catalog,dir_jointstation)\nKeyword Arguments:\n\nâ€˜ForecastingPhaseâ€™\n\nCatalog will be filtered according to this parameter.\nIt can be a N by 2 datetime array with its size identical to the training phases (trnphase), specifying the time ranges of N forecasting phases.\nIt can be â€˜calendarDurationâ€™ or â€˜durationâ€™, saying T. In this case, saying the last day of the training phase is trnphase(i, end), the forecasting phases are set to start from trnphase(i, end) + 1, and end at trnphase(i, end) + T.\nâ€˜autoâ€™. In this case, forecasting phases are set to be as long as possible. That is, until the last day where tsAIN is available.\nDefault is one calendar year: calyears(1).\nAlso see formatForecastingPhase().\nNoted that the actual ProbabilityTime in the output is extended according to the maximum of leading time (Tlead) and predicting time (TPred) model parameters, to maximize the extent that the model can predict. For details, please see refer to the source code of jointstation for how ProbTime is defined.\n\nâ€˜OverwriteFileâ€™\n\nWhether to overwrite existing output files or not.\nDefault is true.\n\nâ€˜ModelSelectâ€™\n\nsee bestmodel()\n\nâ€˜ModelSelectOPâ€™\n\nsee bestmodel()\n\nâ€˜ChooseBestâ€™\n\nDefine the number of maximum best models for each station to be applied.\nDefault is 10, which means we pick the models of top 10 fitting degrees each station for calculating predicted TIP(s).\n\nâ€˜CombinationNumberâ€™\n\nDefine the total number of random combinations among the best models of each station for joint-station TIP calculation.\nDefault is 500, which means for every station a random permutation of ranking numbers (based on the fitting degree) of the best models is performed with each sequence of ranking number having 500 elements, and the ith joint-station model parameter combination is thus from the best models of each station indexed by the ith element of each permutation.\n\n\nInput and output:\n\nmolscore3 takes anomaly indices from dir_tsAIN, earthquake catalog and station information from dir_catalog, and ranked model form dir_molchan.\nThe output probability is saved in dir_jointstation.\n\n\n\nmolscore3_parfor\nmolscore3_parfor is the parallel computing version of molscore3, it takes the same input arguments and supports all documented keyword arguments as molscore3."
  },
  {
    "objectID": "doc_library/index.html#load-raw-data-and-convert-it-into-a-standard-format",
    "href": "doc_library/index.html#load-raw-data-and-convert-it-into-a-standard-format",
    "title": "Library",
    "section": "Load raw data and convert it into a standard format",
    "text": "Load raw data and convert it into a standard format\næ¨™æº–æ ¼å¼è³‡æ–™è¡¨ç¤ºæ‡‰åŒ…å«åƒ…æœ‰ä¸€å€‹æ¬„ä½çš„æ ¼å¼åŒ– matfileï¼Œè©²æ¬„ä½åç¨±å¯ä»»æ„é¸æ“‡ã€‚å‡è¨­æ¬„ä½ç‚º Mï¼Œå‰‡ M å¿…é ˆæ˜¯ä¸€å€‹çŸ©é™£ï¼Œå…¶æ™‚é–“å’Œè³‡æ–™çš„æ¬„ä½ç´¢å¼•éœ€ä¾æ“šè³‡æ–™é¡å‹ç”±å‡½æ•¸ fmt.colindex2dataï¼ˆåƒè¦‹ fmtï¼‰åˆ†é…ã€‚\n\n\n\n\n\n\nWarning\n\n\n\néœ€æ³¨æ„ï¼Œfmt.colindex2data è¿”å›ä¸€çµ„ç”¨æ–¼æ¨™æº–æ ¼å¼è³‡æ–™çš„ç´¢å¼•ï¼Œè€Œ columnindï¼ˆåƒè¦‹ ä¸‹æ–¹çš„ docstringï¼‰å‰‡è¿”å›ä¸€çµ„ç”¨æ–¼åŸå§‹è³‡æ–™çš„ç´¢å¼•ã€‚\n\n\næ¨™æº–æ ¼å¼è³‡æ–™çš„å‘½åè‡³é—œé‡è¦ã€‚ å¦‚éœ€äº†è§£ç´°ç¯€ï¼Œè«‹åƒè€ƒä»¥ä¸‹ docstring ä¸­çš„ standarddataname ä»¥äº†è§£å‘½åè¦å‰‡ã€‚\n\n\n\n\n\n\nDocstring\n\n\n\n\n\n\n\n\nconv_gemsdata\nconv_gemsdata(dir_gems_raw, dir_data, dir_catalog) read original GEMSâ€™s data (e.g., 2012_02_07_16_45_00.dat) in dir_gems_raw, merge and convert them to the standard format for GEMS-MagTIP.\nThe GEMSâ€™s raw data is recorded at local time (UTC+8), and conv_gemsdata converts the time to UTC time.\nAlso see \"read_gemsdata.m\". Example:\ndir_gems_raw = 'rawdata/GEMSdat';\n% where the individual data locates in for example:\n% 'rawdata/GEMSdat/em10/REC/Y2012/M02/D07/2012_02_07_16_45_00.dat'\ndir_data = 'dataStandard/GE';\ndir_catalog = 'spreadsheet'; % for obtaining the station information (\"station_location.mat\");\nconv_gemsdata(dir_gems_raw, dir_data, dir_catalog);\nKeyword Argument:\n\nâ€˜FilterByDatetimeâ€™: See conv_geomagdata.\n\n\n\nconv_geomagdata\nThe original geomagnetic data (which are those in â€œ.csvâ€ format being something like â€œ2008010300.KMâ€ or â€œ20190307.LYâ€) should be converted to a standard format before any calculation. conv_geomagdata(dir_mag_raw, dir_data) read original data in dir_mag_raw and save them in the standard format at the directory dir_data.\nKeyword Argument:\n\nâ€˜ContinueFromLastâ€™: Default is false. If true, it compares the names of all old files in the dir_mag_raw and the new files in dir_data before conversion to avoid files that are already being converted to be converted again. This additional procedure may take several hours depending on the size of database; a more efficient way for avoiding repeated processing is to manually specify â€˜FilterByDatetimeâ€™. See below.\nâ€˜FilterByDatetimeâ€™: Only convert the files in the assigned time range(s). It supports:\n\nA datetime. For example, when 'FilterByDatetime', datetime(2010,10,10), only files with time tag being or after 2010-Oct-10 will be converted.\nN by 2 datetime array, for example,\n'FilterByDatetime', [datetime(2009,12,10), datetime(2010,10,10);...\n                     datetime(2013,12,10), datetime(2017,10,10)];\n, only the files in the two time ranges [2009-Dec-10, 2010-Oct-10] and [2013-Dec-10, 2017-Oct-10] will be converted; otherwise, ignored.\n\nâ€˜Testâ€™: It take only the assigned ratio (0-1) of data (files) in the directory dir_mag_raw. The files are randomly chosen. This option should only be applied when you want to test your code for reducing the overall computing time. Default is 0 (when the assigned value for â€˜Testâ€™ is \\(\\leq 0\\) or \\(\\geq 1\\), there is no reduction in the data list).\n\nNOTICE:\n\nFiles in the original format must be uniquely named as â€˜20200101.HCâ€™ or â€˜2020010109.HCâ€™ for example.\nIf not uniquely named, such as â€˜../HC/20200101.txtâ€™, â€˜../CS/20200101.txtâ€™, the second one will be regarded as a duplicated file and be moved out to an alternative folder (dir_alt)\nevery file should have its extension as the code of the corresponding station, e.g.Â â€˜20200101.HCâ€™ is correct; â€˜20200101.txtâ€™ is not valid and an error will occur.\n\n\n\nreadgems\nA general function for reading original gems data. It dispatch the task to the specified function according to file extension.\n\n\nread_gemsdat\nread yyyy_mm_dd_HH_MM_SS.dat from GEMS developed by AnaSystem The following is GEMS.dat format: Header is the first 100 bytes. All parameters in header is in a unit of 2 bytes Hence, the header has 50 fields.\n\n0-11 bytes is for date\n0-1: year\n2-3: month\n4-5: day\n6-7: hour\n8-9: minute\n10-11: second\n12-13: sampling rate\n14-15: Channel Options (15 has 4 CHs,255 has 4 CHs,7 has 3 CHs,3 has 2 CHs)\n16-99 bytes are padded by zero, for future use.\n\nFrom the 100th byte on, every 4 byte is used to restore data. The order is TimeStamp, Ch1, Ch2, Ch3, Ch4. If one channel is not used, skip it. e.g., only use chn1 and chn3, then recording order is TimeStamp, Ch1, Ch3, TimeStamp, Ch1, Ch3, and so on. In every cycle, TimeStamp is a 4-byte integer, time drift from the header time, unit is minisecond. channelâ€™s data is 4-byte single-precision float. Note that the byte order of all data is â€œlittle endian.â€ The value of voltage is between -10 V and 10 V.\nfunction [data, header] = read_gemsdat(absolute_FileName) input: absolute_FileName: string, absolute full file name output: data = [time,chn1,chn2,chn3,chn4], N x 5 header = [yyyy;mm;dd;HH;MM;SS.SS;fs;chnOPT;â€¦] built-in func: fopen, fclose, fread, fseek self-defined func:\nusage:\n[data, header] = read_gemsdat('g:\\GEMSdat\\em10\\REC\\Y2012\\M02\\D07\\2012_02_07_16_45_00.dat');\nOrigin\n\nreadanasystem.m\nAuthor: Han-Lun Hsu\n\nFirst modification\n\nMatlab version: 2018b\nAuthor: Hong-Jia Chen (redhouse6341@gmail.com)\nDate: 2018/07/01\n\nSecond modification\n\nMatlab version: 2021b\nAuthor: Hong-Jia Chen (redhouse6341@gmail.com)\nDate: 2021/10/11\n\n\nThe docstring is revised by Tsung-Hsi Wu in 2024.\n\n\n\ngeoelectric_projection\nOne field data of any direction can be determined by data of another two directions E(phi)=[-E1*sin(phi-theta2)+E2*sin(phi-theta1)]/sin(theta2-theta1) In this framework, make sure Common Electrode is negative for all channels That is, A is CH01+, B is CH02+, C is CH01- and CH02- function [E] = geoelectric_projection(phi, E1, theta1, E2, theta2) input: phi, theta1, theta2 = â€˜degreeâ€™ from the north, positive for clockwise E1, E2 = field data of any two direction output: E = field data of the specific direction phi phi = 0 means north phi = 90 means east built-in func: sind numel user-defined func:\nusage:\n[E_EW] = geoelectric_projection(90, E_chn1, 15, E_chn2, 120); \n[E_NS] = geoelectric_projection(0, E_chn1, 15, E_chn2, 120); \n% where  East is positive;  North is positive\nReference\n\nTakahashi et al.Â (2005): ULF Electromagnetic Environment at Southern Boso Peninsula : Signal Discrimination of the Geoelectromagnetic Data\n\nOrigin\n\nMatlab version: 2018b\nAuthor: Hong-Jia Chen (redhouse6341@gmail.com)\nDate: 2020/09/02\n\n\nThe docstring is revised by Tsung-Hsi Wu in 2024.\n\n\n\ncolumnind\nReturn column indices for time, data and others according to the type field on the file name of standard format GE/GM data.\n\n\nstandarddataname\n[fname] = standarddataname(stnm, dtstr, type_j) returns the file name of the standard data format. For example, standarddataname('HUAL', '20120202', 'GEMS0') returns stn[HUAL]dt[20120202]type[GEMS0].mat.\n\n\nwrite_data\nGiven the reference tag strcheckwith (that automatically updated inside this function) and the reference tag strj (defined outside the function), write_data creates a new file fname if they are different, and write M into the same matObj if they are the same.\nExample In the following example, New matfile matObj is created in the first loop with matObj.M = M. In the subsequent loops, new data M will be appended to the same matObj.M until datestr is updated.\ndtstr0 = '00000000';\nmatObj = 0;\n    for j = 1:height(table_i)\n        dtstr_j = table_i{j, 'datestr'}; \n        ...\n        [matObj, dtstr0] = write_data(M, matObj, dtstr0, dtstr_j, dir_i, fname, dir_alt);\n    end"
  },
  {
    "objectID": "doc_library/index.html#available-preprocessing-functions",
    "href": "doc_library/index.html#available-preprocessing-functions",
    "title": "Library",
    "section": "Available Preprocessing Functions",
    "text": "Available Preprocessing Functions\nåœ¨ GEMS-MagTIP ä¸­ï¼Œè¨Šè™Ÿè™•ç†é€šéé è™•ç†å‡½æ•¸é€²è¡Œï¼Œé€™äº›é è™•ç†å‡½æ•¸æ˜¯ä½æ–¼ src/preprocess çš„ç‰¹æ®Šå‡½æ•¸ã€‚ no å‡½æ•¸çš„åŠŸèƒ½æ˜¯å¾çµ¦å®šçš„æª”æ¡ˆè·¯å¾‘åŒ¯å…¥è³‡æ–™ï¼Œé€™æ˜¯å¿…é ˆçš„ã€‚ æ‚¨å¯ä»¥ä½¿ç”¨ prplist = prpfunctions() åˆ—å‡ºæ‰€æœ‰çš„é è™•ç†å‡½æ•¸ã€‚ æ¿¾æ³¢å‡½æ•¸ï¼ˆä¾‹å¦‚ ULF_Aã€ULF_Bï¼Œåœ¨ prplist ä¸­ï¼‰å…±ç”¨æ ¸å¿ƒå‡½æ•¸ generalfilterprocessï¼Œè©²å‡½æ•¸å°‡ loadfilters çš„è¼¸å‡ºä½œç‚ºè¼¸å…¥ã€‚\n\né è™•ç†å‡½æ•¸çš„åŠŸèƒ½æ˜¯ä»€éº¼ï¼Ÿ\n\nåŒ¯å…¥è³‡æ–™ï¼ˆå³ Mï¼‰\nåŸ·è¡Œä¸€äº›é è™•ç†ï¼ˆä¾‹å¦‚å¸¶é€šæ¿¾æ³¢ï¼‰\nå°‡è™•ç†å¾Œçš„è³‡æ–™è¼¸å‡ºç‚ºèˆ‡ M å…·æœ‰ç›¸åŒåˆ—æ•¸çš„çŸ©é™£\nåœ¨é è™•ç†å‡½æ•¸ä¸­ä½¿ç”¨ columnind ç²å–æ™‚é–“æ¬„ä½ã€æ•¸æ“šæ¬„ä½ç­‰çš„ç´¢å¼•ã€‚\n\n\n\nå¦‚ä½•å®šç¾©è‡ªè¨‚çš„é è™•ç†å‡½æ•¸èˆ‡ statind é…åˆä½¿ç”¨ï¼Œéœ€ç¬¦åˆä»¥ä¸‹è¦æ±‚ï¼š\n\nç¬¬ä¸€å€‹è¼¸å…¥åƒæ•¸æ‡‰ç‚ºæ¨™æº–æ ¼å¼æª”æ¡ˆçš„è·¯å¾‘ fpathã€‚\nå¾ fpath åŒ¯å…¥è³‡æ–™ã€‚\nç¢ºä¿æ¬„ä½ç´¢å¼•èˆ‡ columnind ç›¸å®¹ã€‚\nå°‡å‡½æ•¸çš„ .m æª”æ”¾ç½®æ–¼ src/preprocess è³‡æ–™å¤¾ä¸‹ (èˆ‡ no.m åŒä¸€å€‹è³‡æ–™å¤¾éšå±¤)ã€‚\n\n\n\nå¦‚ä½•ä½¿ç”¨\n\né€šéstatind éšæ®µçš„ 'Preprocess' æ¥å£ï¼šstatind(..., 'Preprocess', 'ULF_A') (ULF_A å¯ä»£æ›æˆ prpfunctions() æ‰€åˆ—çš„ä»»æ„å‡½æ•¸å)ã€‚\nè¦‹ä»¥ä¸‹ç¯„ä¾‹ã€‚\n\n\n\nç¯„ä¾‹\nå…§å»ºå››å€‹é è™•ç†å‡½æ•¸ï¼Œåˆ†åˆ¥ç‚º BP_35ã€BP_40ã€ULF_A å’Œ ULF_Bï¼›é€™äº›æ¿¾æ³¢å™¨å¯é€é statind éšæ®µä¸­çš„ 'Preprocess' é—œéµå­—åƒæ•¸é€²è¡Œæ‡‰ç”¨ã€‚\nä»¥ä¸‹ç¯„ä¾‹å±•ç¤ºç›´æ¥ä½¿ç”¨ï¼ˆéé€šé statind éšæ®µçš„ 'Preprocess' æ¥å£ï¼‰BP_35 çš„æ–¹æ³•ï¼š\nfpath = 'D:\\GeoMag (main)\\GeoMag_GO\\KUOL\\stn[KUOL]dt[20150714]type[GEMS].mat';\nM_out = BP_35(fpath);\nåœ¨æ­¤ç¯„ä¾‹ä¸­ï¼Œè³‡æ–™å¾ fpath åŒ¯å…¥ç‚ºè®Šæ•¸ï¼Œç„¶å¾Œèª¿ç”¨ generalfilterprocessï¼Œé»˜èªä½¿ç”¨ bandpassï¼Œæ¯æ¬¡åŒ¯å…¥è³‡æ–™æ™‚å‰µå»ºä¸€å€‹å¸¶é€šæ¿¾æ³¢å™¨ï¼Œä¸¦å°‡æ¿¾æ³¢å¾Œçš„è³‡æ–™è¼¸å‡ºç‚ºèˆ‡ M å…·æœ‰å®Œå…¨ç›¸åŒæ¬„ä½(ç›´è¡Œ)æ•¸çš„ M_outï¼ˆä½†æ©«åˆ—æ•¸å¯èƒ½æœ‰æ‰€æ¸›å°‘ï¼‰ã€‚\nå¦ä¸€å€‹ç¯„ä¾‹å‰‡æ˜¯æ‡‰ç”¨ç¾æœ‰çš„æ¿¾æ³¢å™¨ï¼ˆä¾‹å¦‚ 'Filter[BP_35]samp[1]stp[093].mat'ï¼‰æ–¼ dir_filter ä¸­ï¼ˆå¦‚æœå¯èƒ½ï¼‰ï¼š\nfpath = 'D:\\GeoMag (main)\\GeoMag_GO\\KUOL\\stn[KUOL]dt[20150714]type[GEMS].mat';\nfiltpaths = datalist('Filter*.mat', dir_filter);\nFOBJ = loadfilters(filtpaths); % load all filters as a struct FOBJ\nM_out = BP_35(fpath, FOBJ);\n\n\n\n\n\n\nDocstring\n\n\n\n\n\n\n\n\nBP_35\nThe preprocessing function that filter the loaded timeseries with 'BP_35' band-pass filter. It applies down sampling to 1 Hz before band-pass filtering ('Downsampling1Hz', true), and applies edge truncations right before output ('EdgeTruncate', 3162); please refer generalfilterprocess for more details. The lower and upper bounds of frequency are [10^(-3.5) 10^(-1.75)] (in unit Hz); please refer fmt.filterRange.\n\n\nBP_40\nThe preprocessing function that filter the loaded timeseries with 'BP_40' band-pass filter. It applies down sampling to 1 Hz before band-pass filtering ('Downsampling1Hz', true), and applies edge truncations right before output ('EdgeTruncate', 10000); please refer generalfilterprocess for more details. The lower and upper bounds of frequency are [10^(-4) 10^(-1.75)] (in unit Hz); please refer fmt.filterRange.\n \n\n\nULF_A\nThe preprocessing function that filter the loaded timeseries with the 'ULF_A' band-pass filter. It applies down sampling to 1 Hz before band-pass filtering ('Downsampling1Hz', true), and applies edge truncations right before output ('EdgeTruncate', 1000); please refer generalfilterprocess for more details. The lower and upper bounds of frequency are [0.001 0.003] (in unit Hz); please refer fmt.filterRange.\n\n\nULF_B\nThe preprocessing function that filter the loaded timeseries with the 'ULF_B' band-pass filter. It applies down sampling to 1 Hz before band-pass filtering ('Downsampling1Hz', true), and applies edge truncations right before output ('EdgeTruncate', 1000); please refer generalfilterprocess for more details. The lower and upper bounds of frequency are [0.001 0.01] (in unit Hz); please refer fmt.filterRange.\n\n\nno\nM_prp = no(fpath) does no preprocessing, loads and returns the data of fpath in the form of matrix.\nOther functions might also depends on no. For example, prpfunctions is dependent on no to get the directory of all functions for preprocessing.\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ngeneralfilterprocess æ˜¯ 'ULF_X' å’Œ BP_X ç³»åˆ—çš„æ ¸å¿ƒå…±ç”¨å‡½æ•¸ï¼›è©³æƒ…è«‹åƒè€ƒæ¿¾æ³¢å‡½æ•¸ã€‚"
  },
  {
    "objectID": "doc_library/index.html#filtering-functions",
    "href": "doc_library/index.html#filtering-functions",
    "title": "Library",
    "section": "Filtering Functions",
    "text": "Filtering Functions\n\n\n\n\n\n\nDocstring\n\n\n\n\n\n\n\n\nautobandpassfilter\nGiven a file of standard format, create and save bandpass filter accordingly. See also fmt; generalfilterprocess.\n\n\nbutterfilt\nButterworth filter.\n\n\nfilterthedata\nM_dataf = filterthedata(M_input,prp_tag,...\n    'SamplingFrequency',fs,...\n    'RemoveOutliers',true);%\nwhere M_input is an n by m array where n is the number of data points, m is the number variable. That is, each row of M_input is a data point; each column is a variable.\n\n\ngeneralfilterprocess\nGiven prp_tag, generalfilterprocess(prp_tag, fpath, 'AvailableFilter', FOBJ) load data from fpath, filter only the data column and return the data as M_prp. The frequency range is inquiried through fmt.filterRange or FOBJ.(prp_tag).(fs_tag).\nIf FOBJ is provided, generalfilterprocess attempts to do filtering with filters in FOBJ; if there is no adequete filter in FOBJ, it applys filterthedata that generates filter for file fpath with warning message.\nOption:\n\n'EdgeTruncate', 1000: Truncate the head/tail by 1000 data points right before output.\n'AbnormalLowValue', 1e-6: Replace data of absolute values less than 1e-6 to NaN.\n\ngeneralfilterprocess involves the following processin; see the docsting therein:\n\nloadfilters for information about FOBJ, fs_tag and prp_tag.\nfmt for fmt.filterRange\nfilterthedata for automatically create a filter and do filtering\nfillNaN for interpolation (which is required before any filtering)\nautobandpassfilter for quickly making and saving filters.\n\n\n\nloadfilters\nF = loadfilters(filtpaths) load filters as a nested structure, that opts = F.(prp_tag).(fs_tag) is compatible to signal.internal.filteringfcns.filterData in bandpass. In which, prp_tag should be in the list of prpfunctions() and fs_tag is the sampling frequency prefixed by â€œfsâ€ (e.g., â€˜fs15â€™ for 15Hz).\nThe simplest way to create and save a filter is apply bandpass to data with a certain set of parameters, set debug point inside bandpass, and save opts in the debug scope. For canoical approaches, see Filter Design in Matlab.\nThe filters should named as â€˜Filter[ULF_A]samp[15]â€¦.matâ€™ for example.\nThe input filtpaths should be a struct having name for file names and fullpath for file paths.\nSee also:\n\nprpfunctions(): list all preprocessing functions that might support F.\nsignal.internal.filteringfcns.filterData (Signal processing package of matlab)\nstatind(__)\n\n\n\ntry_generalfilterprocess\nA try-catch wrapper to avoid aborting execution due to error raised in generalfilterprocess."
  },
  {
    "objectID": "doc_library/index.html#internal-api-for-tip-calculation",
    "href": "doc_library/index.html#internal-api-for-tip-calculation",
    "title": "Library",
    "section": "Internal API for TIP Calculation",
    "text": "Internal API for TIP Calculation\n\n\n\n\n\n\nDocstring\n\n\n\n\n\n\n\n\nTIPArea\nisinS indicates the points of xLon, yLat that are in the range of Rc centered at Lon, Lat. Unit:\n\nxLon (yLat): degree of longitude (latitude).\nRc: kilometer. Noted that Rc is convert to the unit of degree and be the mean of those based on the latitude and longitude of the center respectively. (Hint: when converting km to deg, it depends on latitude and the longitude. For example, at lower latitude, the distance of 1 deg interval in longitude is much larger than that of 1 deg interval at high latitude.)\n\nInput:\n\nxLon (yLat): N by 1 array for longitude (latitude)\nRc: M by 1 array of raddi\nLon, Lat: M by 1 array of the coordinate of centers each.\n\nOutput:\n\nisinS: xLon(isinS),yLat(isinS) specify all the points (clearly non-repeated) that are within the ranges of radii Rc inside the centers specified by Lon, Lat.\n\n\n\nTIPspatialtemporal\nOutput:\n\nisinTS: a S by T logical array specifying spatial-temporal points that are within the ranges of radii Rc inside the centers specified by Lon, Lat, where [Rc, Lon, Lat] = LatLonRc_TIPtrue is a M by 3 array where \\(M \\geq T\\) must be satisfied.\n\n\n\nbestmodel\n[BestModels,BestModelNames,idPermute,molList] = bestmodel(molList,BestN,totalM,StationLocation) filters the best N models out based on fitting degree and perform random permutation of total M combination of them. That is, bestmodel() save the best N (at most) models for each station in BestModels, and gives an array of M elements that are randomly picked from the set of the ranking numbers of the best N (at most) models.\nInput arguments:\n\nmolList: The list of paths to the files of ranked models, which are produced by molscore. Get the molList using datalist(...).\nBestN: The number the models of highest molchan score.\ntotalM: The amount of randomly permuted combinations of the best N models. That is, M is the number of joint-station models. Noted that the first model combination is forced to be the combination of the best model of each station.\nStationLocation: A J by 3 table with the column names being â€˜formatâ€™, â€˜Lonâ€™, â€˜Latâ€™ and row names (i.e.Â StationLocation.Properties.RowNames) the station codes (e.g.Â â€˜TWâ€™, â€˜CSâ€™,â€¦) of the total J stations.\n\nOutput arguments:\n\nBestModels: A J-by-1 cell array containing the best models of total J stations. In each cell there is a table model parameters.\nBestModelNames: An J-by-1 cell array containing station names corresponding to BestModels (also J-by-1 cell array).\nidPermute: The randomly permuted indices for the best models. It is a J by 1 cell array, where each cell contains a M by 1 double array being the indices for the Jth BestModels. Noted that the first element in the M by 1 double array is always 1, which force the first model combination in jointstation() to be the combination of the best model of each station (SEE molscore3()).\nmolList: The list of paths to the files of ranked models, where the files having all molchan scores to be NaN (hence model parameters cannot be ranked) are excluded.\n\nKeyword Arguments:\n\nâ€˜NearbyThresholdâ€™: For some reasons (e.g.Â no target earthquakes at all in the training phase) models cannot be ranked (optimized) for a station (saying â€˜MSâ€™) because all molchan scores are NaN. In this situation, bestmodel will try to find if there is a near-by station within 15 km (in default). If there is, for example, a station â€˜PTâ€™ nearby within 15km of â€˜MSâ€™, then the ranked model â€˜PTâ€™ will be taken instead. That is, in the following process in molscore3, the best models of â€˜PTâ€™ and the AIN based on the geomagnetic data of â€˜MSâ€™ are applied for calculating the probabilities around the station of â€˜MSâ€™.\nâ€˜ModelSelectâ€™: You may filter the table of Molchan scores by using this option. For example, with 'ModelSelect', {'Tpred', 5}, all rows whose Tpred is not 5 will be discard.\nâ€˜ModelSelectOPâ€™\n\nThe operator function for model selecting if 'ModelSelect' have multiple pairs of input argument.\nFor example, with 'ModelSelect', {'Tpred', 5, 'Tlead', 5}, 'ModelSelectOP', @or, all rows with Tpred=5 or Tlead=5 was kept; others, discarded.\nDefault is @or.\n\n\n\n\nconvAIN\nCalculate the total amount of anomaly indices of each day. That is, saying we have two statistical indices S and K, and the total amount of anomaly indices is less or equal than 2. It is the â€˜update_tsAINâ€™ of the previous version.\nExample:\n[sum_tsAIN, sum_validateIndex] = convAIN(tsAIN.Athr, tsAIN.validateIndex)\nFor each Athr we have one anomaly index (true or false) and validation index (true or false) per day per variable, and the output is the number of â€œtruesâ€ per day. Usually Athr = 1:10, so the output will be a 10 by 1 cell in each there is a N by 1 double; N is the length of the DateTime series.\nInput arguments:\n\ntsAIN.Athr or tsAIN.validateIndex: A 1-by-10 structure array. See anomalyind for more information.\n\nOutput arguments:\n\nsum_tsAIN or sum_validateIndex: A 10-by-1 cell array corresponding to \\(A_{thr} = 1:10\\). In each cell, there is a N-by-1 double array being the sum of anomaly indices or the sum of valid indices of N days.\n\n\n\ndt_TIP_true\n[dt_TIPtrue,TIPtime,TIP] = dt_TIP_true(DateTimeSAT,vlSAT, Tthr,Tlead,Tpred) return the datetime where TIP is true.\nInput arguments:\n\nDateTimeSAT: M-by-1 datetime array for sum of anomaly days\nvlSAT: M-by-1 double array for the values of sum of anomaly days (the anomaly days is summed in the moving window of Tobs)\nTthr: the threshold related to the number of anomaly days in Tobs\nTlead: the leading window right before the prediction window\nTpred: the window of prediction (where TIP is true or false according to the number of anmalies in the corresponding Tobs window)\n\nOutput arguments:\n\ndt_TIPtrue: the datetime where TIP is true\nTIPtime: an N-by-1 datetime array paired with the TIP array\nTIP: an N-by-1 logical array of Time of Increased Probability\n\nThe variable dt_TIPtrue may exceeds the last day of DateTimeSAT, while TIPtime is truncated to not exceed DateTimeSAT(end) in molscore, because in training phase datetime out of DateTimeSAT is assumed to be out of the time range of available earthquake catalog.\nA schematic illustration of the input/output variables:\nsum_validateIndex_all_a_dti (2nd input argument in sumanomalyind)\n               1100111011000001010010000000001010000000 (for example) \nDateTime_dti   tttttttttttttttttttttttttttttttttttttttt\nTobs length    |-----|  (Tobs=7, for example) \nTlead length          |-------| (Tlead=9, for example) \nvlSAT                5445543222122233222221112122344332 (for example) \nDateTimeSAT index    123456789.........................         \nDateTimeSAT    |Tobs |--------------------------------|         \nTIPtime/TIP    |Tobs || Tlead ||--------------------------------------|\n                               â†‘                |Tobs || Tlead ||Tpred| \n                   Tpred start â†‘        last AIN data â†‘     Tpred end â†‘    \n\n\ndt_TIP_valid\ndt_TIP_valid gives loosely valid TIP time and strictly invalid TIP time. There are two possibilities for a TIP false: one is that the anomaly index number (AIN) is below the threshold, and the other is that AIN is NaN since anything in comparison with a NaN results in a false. The later we called it an â€˜invalidâ€™ TIP time/day.\nExample:\n[TIPtime1,TIP_valid,dates_TIPvalid_st,dates_TIPinvalid_st] = ...\ndt_TIP_valid(DateTimeSAT,sum_validateIndex_all_a_dti,Tobs,Tlead,Tpred)\nThis gives the datetime where there is at least one data in the Tobs and hence TIP false is a valid false.\nInput arguments:\n\nDateTimeSAT: see sumanomalyind()\nsum_validateIndex_all_a_dti: the sum_validateIndex in convAIN()\nTobs: the observation time window right before the leading window (Tlead).\nTlead: the leading window right before the prediction window\nTpred: the window of prediction (where TIP is true or false according to the number of anmalies in the corresponding Tobs window)\n\nOutput arguments:\n\nTIPtime1: a 1-d datetime array for TIP_valid\nTIP_valid: a 1-d logical array indicating whether the TIP is valid or not.\ndates_TIPvalid_st: Returns the datetimes of where the TIP have a meaningful true/false.\ndates_TIPinvalid_st: Returns the datetimes of where the TIP have a meaningless false. (If TIP is true, then the day should always be valid)\n\nAbout the meaningful and meaningless â€˜falseâ€™, see the comments in anomalyind()\nRecalling that sum of AIN is the sum of anomaly index calculated in the moving time window of length Tobs, and the dates DateTimeSAT(sum_AIN_valid) denotes the end day of Tobs where at least one of the anomaly index in the Tobs window is meaningful, we have the following example where Tlead = 9, Tobs = 7, and Tpred = 3, for explicitly demonstrates how the TIPâ€™s valid times are calculated:\nsum_validateIndex_all_a_dti\n              '1100111011000001010010000000001010000000' (for example) \nDateTime_dti   tttttttttttttttttttttttttttttttttttttttt|\nDateTimeSAT          tttttttttttttttttttttttttttttttttt|\nsum_AIN_valid        1111111111111111111110001111111110|\ndt_AIN_valid         ttttttttttttttttttttt   ttttttttt |\n               |Tobs ||&lt;--a---&gt;|                       |&lt;--b-----&gt;|\nTIPtime                        tttttttttttttttttttttttttttttttttttt\nTpred moving window            |c|                              |c|\n                               | the same length as DateTimeSAT |\nTIPvalid_0                     123456789........................\n                                \\\\\\\\\\\\\\\nTIPvalid_1                       3456789..........................\n\nTherefore, \ndt_TIPvalid = unique(TIPtime([1:3,2:4,3:5,....]))\n\n% t denotes a datetime object\n% a = Tlead+1 = idinc2predstart\n% b = Tlead+Tpred = idinc2predend\n% c = Tred\n% dt_AIN_valid is DateTimeSAT(sum_AIN_valid), and sum_AIN_valid is a.k.a Tobs_TF.\n% TIPvalid_0 (_1) is a.k.a. TIP_TF_0 (_1)\n\n\neqktip1\n[EQK,TIP, TIPtime] = eqktip1(eqMR,eqDateTime, DateTimeSAT,vlSAT, ...\n                   Tthr_iMod,Tlead_iMod,Tpred_iMod, Mc_iMod,Rc_iMod)\nprovides 1 dimensional logical array of target earthquakes (EQK) and Time of Increased Probability (TIP), corresponding to the 1-d datetime array TIPtime.\nInput arguments:\n\neqMR: a N by 2 array of all-combination of model magnitudes and radii of detection, with the first column being magnitude and second column the radius of detection.\neqDateTime: a N by 1 cell array. Each cell contains the datetime of target earthquakes satisfying the corresponding row of eqMR; i.e., being larger than eqMR(i,1) and within eqMR(i,2).\nDateTimeSAT, vlSAT: see sumanomalyind.\nTthr, Tlead, Tpred: see dt_TIP_true.\nMc_iMod: the current model magnitude.\nRc_iMod: the current model radius of detection.\n\nOutput arguments:\n\nEQK: the M-by-1 logical array for whether there is/are target earthquakes in the day.\nTIP: an M-by-1 logical array of Time of Increased Probability\nTIPtime: an M-by-1 datetime array paired with the TIP and EQK array\n\nSee also:\n\n[~,eqMR,eqDateTime] = isearthquakeinrange(...) in molscore\n[DateTimeSAT,vlSAT] = sumanomalyind(...) in molscore\n\n\n\nget_modelparam\nUse [var1, var2, ...] = get_modelparam(BestModels, 'name1', 'name2',...) to get specific model parameters uniquely. BestModels is the output of bestmodel().\nExample:\n\nTpreds, Tleads = get_modelparam(BestModels, 'Tpred', 'Tlead')\n\n\n\njointstation\njointstation calculates hit rates, alarmed rates, and spatial probability.\nExample:\nWhen it is applied for calculating the hit rates of the training phase:\nHitRates_trn = jointstation(BestModels,BestModelNames,idPermute,...\n             sum_tsAINs,sum_validateInds,DateTime_dti,...\n             CWBcatalog,'CalculateHitRate',true);\nWhen it is applied for calculating the forecasting probabilities:\n[HitRates_frc, AlarmedRates_frc, SpatialProbability, xLon, yLat, ...\n    validStationTime, ProbTime, TIP3, TIPvalid3, EQKs, Other]...\n    = jointstation(BestModels,BestModelNames,idPermute,...\n         sum_tsAINs,sum_validateInds,DateTime_dti,...\n         CWBcatalog,'CalculateHitRate',true,...\n         'CalculateAlarmedRate',true,'CalculateProbability',HitRates_trn,...\n         'StationLocation',StationLocation, 'Verbose', true);\nKeyword Arguments:\n\nâ€˜CalculateHitRateâ€™: Whether to calculate the hit rates. Default is false.\nâ€˜CalculateAlarmedRateâ€™: Whether to calculate the alarmed rates. Default is false.\n\nIf â€˜CalculateProbabilityâ€™ is true, â€˜CalculateAlarmedRateâ€™ will be automatically set to be true since alarmed rates are essential to probability calculation.\n\nâ€˜CalculateProbabilityâ€™: Whether to calculate the spatial probability. Default is false.\nâ€˜StationLocationâ€™:\n\nA J by 3 table with the column names being â€˜formatâ€™, â€˜Lonâ€™, â€˜Latâ€™ and row names (i.e.Â StationLocation.Properties.RowNames) the station codes (e.g.Â â€˜TWâ€™, â€˜CSâ€™,â€¦) of the total J stations.\nIf â€˜CalculateAlarmedRateâ€™ is true, â€˜StationLocationâ€™ must be specified; otherwise it is impossible to obtain alarm rates.\nDefault is 0.\n\n\nInput arguments:\n\nBestModels: A J-by-1 cell array containing the best models of total J stations. In each cell there is a table model parameters.\nBestModelNames: An J-by-1 cell array containing station names corresponding to BestModels (also J-by-1 cell array).\nidPermute: The randomly permuted indices for the best models. See bestmodel().\nsum_tsAINs: A J-by-1 cell array with each cell corresponding to BestmodelNames. See loadAIN().\nsum_validateInds: A J-by-1 cell array with each cell corresponding to BestmodelNames. See loadAIN().\nDateTime_dti: A T by 1 datetime array for the time series in sum_tsAINs and the sum_validateInds.\nCWBcatalog: A table of earthquake catalog. You may load CWBcatalog using only1field([dir_catalog filesep 'catalog.mat']).\nVerbose: Output an additional struct of Other variables.\n\nOutput arguments:\n\nHitRates, AlarmedRates: M by 1 array, being the hit rates (alarmed rates) of each combination of best models. M is the amounts of total combinations (the totalM in bestmodel()). They are AlarmedRateForecasting and HitRatesForecasting of molscore3â€™s output.\nSpatialProbability: A S by T array of the temporal-spatial forecasting probabilities. It is the output variable Probability of molscore3().\nxLon (yLat): The longitudes (latitudes) of all spatial points as a S by 1 array. It is the output variable ProbabilityLon (ProbabilityLat) of molscore3().\nvalidStationTime: A T by J table of the ratio of valid models each day each station. This is for plotProbability(), that the ratio will be demonstrated as gradient color in the marker of each station. If the ratio is zero, the marker on map will be hollow. It is the output variable validStationTime of molscore3().\nTIP3: A S by T TIP array for the first model (out of the total M models). Since the first element of each cell in idPermute is always 1, indicating the best model, TIP3 is essentially the TIP array calculated according to the best model parameter.\nTIPvalid3: A spatial-temporal logical array indicating whether a point (s,t) of TIP true or false is meaningful or not. This is also a S by T array.\nProbTime: A 1 by T datetime array for TIP3, TIPvalid3 and SpatialProbability. This is the ProbabilityTime of molscore3â€™s output.\nEQKs: The list of target earthquake, with each column\n\ntime, Lon, Lat, Depth, Mag: The time, longitude, latitude, depth and magnitude (\\(M_L\\)) of the target earthquake.\nInStation: Indicates the target earthquake is of which station.\nEqkDist: The distance between the station (as specified by InStation) and hypocenter of the target earthquake. Also see simpleStationEQKdist3D.\n\nOther: The additional output when â€˜Verboseâ€™ is true.\n\nOther.nEQK: The number of target earthquakes for each model in forecasting phase.\nOther.areaTIP: The total area (spatial + temporal) of TIP for each model in forecasting phase. See TIPspatialtemporal and TIPArea.\nOther.nEQK .* HitRates is the number of hitted earthquakes in this forecasting phase.\nOther.areaTIP .* AlarmedRates is the total amount of alarmed TIP area in this forecasting phase.\nNoted that it is nonsesnse to set â€˜Verboseâ€™ to be true when â€˜calculateHitRateâ€™ and â€˜calculateAlarmedRateâ€™ are false.\n\n\n\n\nloadAIN\n[sum_tsAINs,sum_validateInds,DateTime_dti,AthrList] =\nloadAIN(dir_tsAIN,BestModelNames,TimeRange)\nload tsAIN, calculate the summation of anomaly index of each day, and truncate the time series to TimeRange.\nIf class(BestModelNames) == 'char', for example, â€˜CSâ€™, the output sum_tsAINs and sum_validateInds are the 10 by 1 cell array directly, instead of a M by 1 cell array inside the J by 1 cell array where J = 1.\nInput arguments::\n\ndir_tsAIN: the directory for the saved AIN data. See anomalyind().\nBestModelNames: an J-by-1 cell array containing station names corresponding to BestModels (also J-by-1 cell array).\nTimeRange: a two-element datetime array.\n\nOutput arguments::\n\nsum_tsAINs: a J-by-1 cell array with each cell corresponding to BestmodelNames. In each cell there is a 10-by-1 cell corresponding to the list of \\(A_{thr}\\) (AthrList = 1:10), being the timeseries of the summation of anomaly index of each day.\nsum_validateInds: a J-by-1 cell array with each cell corresponding to BestmodelNames. In each cell there is a 10-by-1 cell corresponding to the list of \\(A_{thr}\\) (AthrList = 1:10), being the summation of the indicators for the valid statistical indices of each day.\n\n\n\nmodparam\nIn GEMS-MagTIP, model parameters defines TIP and target earthquakes (EQK). [PredParam,varargout]=modparam() generate the whole set of model parameters that are going to be used in the training phase by molscore.\nKeyword Arguments:\n\nâ€˜Rcâ€™: Radius (range) of detection in unit kilometer. Default is [20:10:100])\nâ€˜NthrRatioâ€™:\n\nThe ratio threshold to be converted to the number of anomalous statistic index every day.\nâ€˜NthrRatioâ€™ should be calculated automatically in molscore() according to the maximum possible number of statistic indices among the anomaly index calculated by anomalyind().\nNthr is the threshold (integer) for the number of anomalous statistic indices each day.\nDefault is [0.01, 0.99], which is for the situation where the maximum possible Nthr is \\(\\leq 2\\) (i.e., to be [0, 1]). If you have the maximum possible Nthr to be \\(\\leq 3\\) (i.e, Nthr = [0 1 2]), â€˜NthrRatioâ€™ should be assigned to be [0.01, 0.49, 0.99] for example.\n\nâ€˜Ptthrâ€™: Ptthr defines Tobs through Ptthr = Tthr/Tobs. Default is [0.1:0.1:0.5].\nâ€˜Tobsâ€™: The length of observation moving window. Default is [5:5:100];\nâ€˜Tpredâ€™: The length of prediction moving window.\nâ€˜Tleadâ€™: The length of leading window, the time gap that is for the period of silent (no-anomaly) right before big earthquakes.\n\nDefault is [0:5:100].\n\nâ€˜Mcâ€™: The magnitude threshold. Default is 5, which means only events of \\(M_L \\geq 5\\) will be considered as target earthquakes.\nâ€˜Testâ€™:\n\nIf true or 1, then the PredParam is reduced to 1000 randomly picked models from the default combination.\nIf it is a positive integer N other than 1, the predParam is reduced to N randomly picked models.\nDefault is 0.\n\nâ€˜Seedâ€™: the seed for the random selection while â€˜Testâ€™ is enable.\n\nSeed must be a nonnegative integer seed less than 2^32.\nIf seed is less than zero, the random selection has its result different everytime.\n\n\nOutput:\n\nPredParam: The GEMSTIP/MagTIP models of total 8 free parameters: G = [Mag,Rad,NthrRatio,Athr,Tthr,Tobs,Tpred,Tlead].\n\nExamples: - [PredParam, columnNames] = modparam('OutputFormat','double'); - [PredParam_table] = modparam('OutputFormat','table');\n\n\nshift2TIPtime\n[dt_true_in_TIP, TIPtime] = shift2TIPtime(DateTimeSAT,Tobs_TF,Tlead,Tpred) gives the date time array in the domain of TIPtime, where the trues in TIPtime are defined in Tpred window according to the data in Tobs window. Tobs_TF:\n\ntrues or falses according to the data in Tobs moving window.\nthese true-falses should be exactly the same size of DateTimeSAT, where DateTimeSAT is the moving-windowâ€™s time tags (at the last day of the moving time window)\ne.g., vlSAT&gt;=Tthr_iMod\ne.g., logical(MovingWindowSum(sumvalidateIndexalladti,Tobs))\n\n\n(these examples are taken from see dtTIPtrue.m and dtTIPinvalid.m)\n\ndt_true_in_TIP: the corresponding trues in the TIP time domain.\n\n\nsortModelBy\nSort model names by a certain column value. Example: [sortedModelNames, I] = sortModelBy('Lat','descend',ModelNames,TheTable);\n\n\nsumanomalyind\n[DateTimeSAT,vlSAT] = sumanomalyind(DateTime_j,sum_tsAIN_k,Nthr_array,Tobs_i) calculate sum of anomaly day (vlSAT) and its corresponding datetime series (DateTimeSAT). It is simply the moving-window sum of the sum_tsAIN_k timeseries, where the moving-window length is Tobs_i; in which, i stands for \\(i_{th}\\) model, j for \\(j_{th}\\) station, and k for \\(k_{th}\\) threshold \\(A_{thr}\\). Of coursely, the number of elements of the output timeseires (DateTimeSAT) will be Tobs_i - 1 less than the input timeseries (DateTime_j or DateTime_dti); i.e., length(sum_tsAIN_k) - length(vlSAT) =  Tobs_i - 1.\nInput arguments:\n\nDateTime_j: the datetime array for sum_tsAIN.\nsum_tsAIN_k: the sum of anomaly statistical indices each day.\nNthr_array: The thresholds for sum_tsAIN_k calculated according to NthrRatio. Nthr is known as the threshold of the total daily amount of anomaly statistical indices.\nTobs_i: the observation window of model i.\n\nOutput arguments:\n\nDateTimeSAT: M-by-1 datetime array for sum of anomaly days\nvlSAT: M-by-1 double array for the values of sum of anomaly days (the anomaly days is summed in the moving window of Tobs)\n\nSee also:\n\nconvAIN for more details about sum_tsAIN_k.\n\n\n\ntruncateTIPtoSAT\nInternal API associated with the truncation of TIP array to the datetime array for the sum of anomaly indices."
  },
  {
    "objectID": "doc_library/index.html#format",
    "href": "doc_library/index.html#format",
    "title": "Library",
    "section": "Format",
    "text": "Format\n\n\n\n\n\n\nDocstring\n\n\n\n\n\n\n\nfmt\nfmt is a class that\n\nstores all constant names\nstores all constant variables\n\nthat enables you to modify or extend some contents without breaking other functionalities.\nGEMS-MagTIP depends on fmt to load a variety of intermediate data, including earthquake catalog, station information table and the input data of the standard format. fmt save constant names and variables as properties (Constant) that they can be available in global scope. fmt also have static methods for acquiring information such as the column indices indicating the time vectors and recorded values of the input data of different types.\nproperties (Constant):\n\nInfoFileName_molscore = '[MolchanScore]Information.mat': name to the intermediate file in the session of training (model optimization)\nInfoFileName_anomalyind = '[tsAIN]Information.mat': name to the intermediate file in the session of calculating anomaly indices\nInfoFileName_jointstation = '[JointStation]Information.mat': name to the intermediate file in the joint-station method session\nInfoFileName_statind = '[StatisticIndex]Information.mat': name to the intermediate file in calculating Statistic Index\ncatalogFileName = 'catalog.mat': file name to the earthquake catalog\nstationLocationFileName = 'station_location.mat': name to the file of station information table\ntag_upperlowerthreshold = 'ULthr': tag for upper- and -lower threshold defined by Athr\ndatestrFormat = 'yyyymmdd': the format for converting datetime to string tags (dt)\ndatetimeInputFormat = 'yyyyMMdd': the format for converting date strings (with tag dt) to datetime\ndatetimeIncrement: the increment of datetime between two consecutive files of the same station and type.\nLatitudeLimit = [21.5 26]: latitude limits of the Taiwan area\nLongitudeLimit = [118 122.5]: Longitude limits of the Taiwan area\ndatatype_mag_1 = {'mFull', 'full'}: \"type\" tag for the full field geomagnetic data (old geomagnetic stations from 2006; â€˜fullâ€™ is for backward compatibility)\ndatatype_mag_3 = {'mTri', 'tri'}: \"type\" tag for the 3 component geomagnetic data (new geomagnetic stations from 2020; â€˜triâ€™ is for backward compatibility)\ndatatype_GEMS_HJ: \"type\" tag for the data of Hong-Jia Chen 2018\ndatatype_GEMS: \"type\" tag for the primitive of Geoelectric data\n\nmethods (Static):\n\ncolindex2data(what_type): returns column indices to time and data part of the loaded matrix. Example: [colind_time, colind_data] = colindex2data('GEMS0')\nfilterRange(filter_tag): returns two values indicating the lower and upper limit of the filter, in the unit of Hz. Example: fmt.filterRange(ULF_A).\ndatasampfreq(what_type): returns the expected Sampling Frequency of a specific file/data type. Example: fs = datasampfreq('GEMS0'). You can obtain expected data points of the day by supposedpts = fs*86400.\nfmtfieldname = datatype_fieldname(what_type): returns the field name for fmt that you can fmt.(fmtfieldname)."
  },
  {
    "objectID": "doc_library/index.html#plotting-functions",
    "href": "doc_library/index.html#plotting-functions",
    "title": "Library",
    "section": "Plotting functions",
    "text": "Plotting functions\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nplotCB\nPlot confidence boundary Make sure xpt0 and Dcb_max are both N by 1 array.\n\n\nplotEQKTIP1\nplotEQKTIP1(dir_tsAIN,dir_molchan,dir_catalog,dir_output) plot one-dimensional TIP time series for each station with target earthquakes (EQK) scattered over the diagram; the results are saved as png files in dir_output.\nKeyword Arguments:\n\nâ€˜ShowTrainingPhaseâ€™: Whether to show the EQK and TIP on the plot. Default is false.\nâ€˜scatterâ€™: Set it true to add an additional layer of scattering points of the same color on the top of every TIP==1. This option allows better visual inspection on whether target earthquakes lay in the area of TIP==1 or not. Default is false.\nâ€˜Rankâ€™: Choose the model by fitting degree ranking for defining EQK and TIP. Default is 1 (plot the EQK and TIP that are defined by the rank 1 model).\nâ€˜OnlyStationsâ€™: Specify only a subset of station to be displayed on the plot; for example, for 'OnlyStations',{'MS','TW'} only the results of these two stations will be displayed. In default, results of all stations will be displayed.\nâ€˜datetimeTickArgumentsâ€™: Manually define the datetime format of the X tick labels. For example, for 'datetimeTickArguments', {\"yy' mmm.\", 1,'months'} the datetime 2012-Nov-12 will be printed as â€œ12â€™ Nov.â€. For more information, see datetime_ticks().\nâ€˜TargetPatternâ€™: See the documentation in plotProbability().\n\n\n\nplotEQKTIP3\nLike plotEQKTIP1, but expand the 3D TIP array into a 2D diagram by squashing spatial coordinates (latitude and longitude) into one.\n\n\nplotFittingDegree\nplotFittingDegree(dir_jointstation,dir_catalog,dir_png) gives fitting degree analysis and molchan diagrams for each training-forecasting phase pair according to the results from molscore3.\n\n\nplotProbability\nplotProbability(dir_jointstation,dir_catalog,dir_out) plots two-dimensional probability forecasting maps; the results are saved as png files in dir_output.\nKeyword Arguments:\n\nâ€˜LongitudeLimitâ€™: The longitude limits of the displayed map. Default is [119 122.5].\nâ€˜LatitudeLimitâ€™: The latitude limits of the displayed map. Default is [21.5 26].\nâ€˜TimeRangeâ€™: Manually assign time ranges or specific dates that must lay in the forecasting phase to plotting probability forecast. If not set, the probability forecast of every available dates will be plotted. The assigned datetime array must be either:\n\nAn N by 2 datetime array specifying N ranges at one time.\nAn N by 1 datetime array specifying N days to be plot.\n\nâ€˜PlotEpicenterâ€™: Whether to plot the epicenter(s) of the target earthquakes on the map. Default is 0.\n\nplotEpicenter, 1: plot target events only (those in Rc).\nplotEpicenter,'all': plot all events even when they are not in Rc.\n\nâ€˜Rigorousâ€™: Whether to drop (ignore) the probability forecasts that are not in the range of the forecasting phases. Default is true. Generally the leading time window (Tlead) is different among models, and the probability can be calculated as far as the Tlead of at least one model covered. However, for the dates out of the forecasting phase, only part of the models are applied thus the probability forecast is weaker.\nâ€˜TargetPatternâ€™: the pattern for filtering the files in dir_jointstation. Default is to look up all files that fits the pattern â€œ[JointStation].matâ€. For example, you can manually specify it as â€[ULF*A]â€ to give plots of that have the tag ULFA in the file name only. The pattern should always begin with â€œâ€ and the last cahracter can never be â€â€. For multiple filtering at once (e.g., '*[ULF_B]*[Tpred-1]'), join the pattern with â€œâ€ and the order is important.\n\n\n\nplot_Rc\nPlot radius of detection around the station.\n\n\nplot_dataoverview\nplot_dataoverview(dir_stat, dir_catalog) plot an overview of all data. Keyword Arguments:\n\nâ€˜SaveFigureToâ€™: the output path\nâ€˜BackgroundColorâ€™: Background color; default is white ([1,1,1])\nâ€˜DatetimeTicksâ€™: The format of datetime ticks on the x-axis.\n\nDefault is {'yyyy-mm',6,'Months'}, which means tick labels are in the format of yyyy-mm and interspaced every 6 months.\n\n\n\n\nplot_epicenter\nplot epicenter [scatter_handle, axes_handle] = plot_epicenter(CWBcatalog,[ax], kwargs...)\nExample\nSLoc = only1field(fullfile(dir_catalog, fmt.stationLocationFileName));\ncheckcatalog(dir_catalog)\nCWBcatalog = only1field(fullfile(dir_catalog, fmt.catalogFileName));\nCWBcatalog = eventFilter(CWBcatalog, 'Magnitude', 5, 'TimeRange', '20220601-20221002');\n\nfigure;\n[sc1, ax1] = plot_station(SLoc,'PlotFunction','map', 'MarkerFaceColor', 'none', 'MarkerEdgeColor', '#D95319', 'StationCode', false); % plot all station\nhold(ax1, 'on');\nplot_epicenter(CWBcatalog, ax1, 'PlotFunction','map'); % plot epicenters\nset(gcf, 'Position', [100 100 792 669]);\n\n\nplot_station\nplot map and station. See plot_epicenter."
  },
  {
    "objectID": "doc_library/index.html#others",
    "href": "doc_library/index.html#others",
    "title": "Library",
    "section": "Others",
    "text": "Others\n\n\n\n\n\n\nDocstring\n\n\n\n\n\n\n\n\nMolchan_CB\n[molt_cb,moln_cb] = Molchan_CB(N,alpha) gives the confidence boundary in molchan diagram, where [molt_cb,moln_cb] are the points defining the boundary on the alarmed-rate-against-missing-rate phase plane.\nInput Arguments:\n\nN: total number of target events/earthquakes\nalpha: 1-alpha is the confidence level. For example, alpha=0.05 means 95% confidence level.\n\nOutput Arguments:\n\nmolt_cb: values corresponding to the alarmed rate\nmoln_cb: values corresponding to the missing rate\n\nHint:\n\nCalculate the \\(D\\) (fitting degree) values by Dcb = 1 - molt_cb - moln_cb\n\n\n\naskquestion\nExample\naskquestion('Hello, would you like to continue? [Y/N]', @(x) strcmp(x, 'Y'))\nHello, would you like to continue? [Y/N]Y\n\nans =\n\n  logical\n\n   1\n\n\ncalcFittingDegree\ncalcFittingDegree(jpathlist) according to the given files (jpathlist) provides the overall alarmed rate, missing rate that allows the calculation of the overall fitting degree. Make sure to provide correct input list of the [JointStation] variable , for example, those have the same ID and are not overlapped in forecasting time interval for each group; otherwise the calculated fitting degree can be unreasonable.\nExample:\ndir_png = 'MyResearch/Figures';\njpathlist = datalist('[JointStation]ID[ou7ud]prp[ULF_B]*.mat', dir_jointstation).fullpath;\n[AlarmedRate, MissingRate, xticklabel, EQKs, TIP3s, TIPv3s,TIPTimes,LatLons] = calcFittingDegree(jpathlist);\nFittingDegrees = 1 - AlarmedRate - MissingRate;\nplotEQKTIP3(dir_png,prp_i, xlabels, EQKs, TIP3s, TIPv3s,TIPTimes, LatLons);\nInput Arguments:\n\njpathlist: a cell array of the full paths of [JointStation] files that are produced by molscore3. You can simpliy obtain the path list by jpathlist = datalist('[JointStation]ID[ou7ud]*prp[ULF_A]*slc[Tpred-10]*.mat',dir_jointstation).fullpath;\n\nKeyword Arguments:\n\nâ€˜GroupTagâ€™: The tag for grouping the files in jpathlist.\nâ€˜GroupNamesâ€™: Results are calculated separately according to the assigned group names; alarmed rate, missing rate and so on are only calculated if the file name contains the assigned group names. For example, for ...,'GroupNames',{'Tpred-1', 'Tpred-5'},'GroupTag', 'slc',..., only the files with their names containing tag â€˜slc[Tpred-1]â€™ and â€˜slc[Tpred-5]â€™ are selected, and the results of those being â€˜Tpred-1â€™ and â€˜Tpred-5â€™ are separately calculated. That is, the output xlabel is {'Tpred-1', 'Tpred-5'} and other output arguments (e.g.Â AlarmedRate) are all cell array of the same dimension as xlabel containing the results of the groups that are calculated separately.\nNoted that You cannot assign â€˜GroupNameâ€™ without assigning â€˜GroupTagâ€™, but assigning â€˜GroupTagâ€™ without assigning â€˜GroupNameâ€™ is OK, in this case the group names will automatically generated and sorted.\n\n\n\ncheckcatalog\n[isvalid, msg] = checkcatalog(dir_catalog) check if catalog.mat/csv exist in dir_catalog, and convert the catalog.csv to catalog.mat. After successfully create catalog.mat, the original catalog.csv will be moved to the folder â€˜original_csvâ€™.\nIf the catalog.csv does not meet the required format, error will occur. The catalog.csv has to suffice the following condtions:\n\nThe â€˜timeâ€™ variable should be in the following format: â€™yyyy/MM/dd\n\nHH:mmâ€™.\n\nOther variables except â€˜timeâ€™ should belong the class of â€˜doubleâ€™.\nBasicaly the following headers (column names),\n\n{â€˜timeâ€™,â€˜Lonâ€™,â€˜Latâ€™,â€˜Magâ€™,â€˜Depthâ€™}, have to exist.\nAliases for the column names in the catalog.csv are allowed; see the Aliases section below.\nKeyword arguments: 'OverwriteOriginal', false: The csv files in â€˜original_csvâ€™ will not be overwritten. Set 'OverwriteOriginal', true if you have version control.\nAliases: For convenience, aliases of the column name of an variable in catalog.csv will be automatically converted:\n\nFor earthquake magnitudes, the header of either {â€˜Magnitudeâ€™, â€˜magnitudeâ€™, â€˜MLâ€™} will be automatically converted to â€˜Magâ€™.\nFor depths, the header of either {â€˜depthâ€™, â€˜depâ€™, â€˜Depâ€™} will be converted to â€˜Depthâ€™.\nFor longitude and latitude, either {â€˜lonâ€™, â€˜longitudeâ€™, â€˜Longitudeâ€™},\n\n{â€˜latâ€™, â€˜latitudeâ€™, â€˜Latitudeâ€™} will be converted to â€˜Lonâ€™ and â€˜Latâ€™, respectively.\nFor convenience, in catalog.csv, if the event time is written in separated two columns â€˜dateâ€™ and â€˜timeâ€™, with format â€˜yyyy-mm-ddâ€™ (or â€˜yyyy/mm/ddâ€™) for â€˜dateâ€™ and â€˜hh:MM:ssâ€™ (or â€˜hh:MMâ€™), they will be merged as a single â€˜timeâ€™ variable sufficing the format mentioned before.\n\n\ncheckstation\n[isvalid, msg] = checkstation(dir_catalog) check if station_location.mat/csv exist in dir_catalog, and convert the station_location.csv to station_location.mat. After successfully create station_location.mat, the original station_location.csv will be moved to the folder â€˜original_csvâ€™.\nIf the station_location.csv does not meet the required format, error will occur. The station_location.csv has to suffice the following condtions:\n\nThe â€˜timeâ€™ variable should be in the following format: â€™yyyy/MM/dd\n\nHH:mmâ€™.\n\nOther variables except â€˜timeâ€™ should belong the class of â€˜doubleâ€™.\nBasicaly the following headers (column names),\n\n{â€˜codeâ€™,â€˜formatâ€™,â€˜Lonâ€™,â€˜Latâ€™} have to exist. In which,\n\nâ€˜codeâ€™ is the code for the station, whereas â€˜formatâ€™ is the full name of the station. For example, â€˜MSâ€™ (code) corresponds to â€˜é¦¬ä»•â€™ (format).\nâ€˜Lonâ€™ and â€˜Latâ€™ are longitude and latitude of the station respectively.\n\nAliases for the column names in the station_location.csv are allowed; see the Aliases section below.\nKeyword arguments: 'OverwriteOriginal', false: The csv files in â€™original*csvâ€™ will not be overwritten. Set 'OverwriteOriginal', true if you have version control. Aliases: For convenience, aliases of the column name of an variable in station*location.csv will be automatically converted:\n\nFor longitude and latitude, either {â€˜lonâ€™, â€˜longitudeâ€™, â€˜Longitudeâ€™},\n\n{â€˜latâ€™, â€˜latitudeâ€™, â€˜Latitudeâ€™} will be converted to â€˜Lonâ€™ and â€˜Latâ€™, respectively.\n\n\nchkans\nCheck the answer in the interaction command-line interface in startup0.m\n\n\nconstructMolInfo\nconstructMolInfo(dir_molchan,InfoId) construct the â€˜[MolchanScore]Information.matâ€™ according to existing [Molchanscore]___.mat files if possible. Use this function only when you are instructed by error messages.\nExample constructMolInfo('./var-output/MolchanScore-O04-Cfl_local', 'OT0qPb')\n\n\nderive_type\nderive_type derives station type from tag stn[...].\n\n\ndirselectassign\ndirselectassign(var_names...) prompts user to select directories in a dialog box, and assigned the selected path to workspace with default variable name. If a variable with the same name as the default name has already in the workspace, its assignment will be ignored (i.e.Â its dialog box wonâ€™t pop out). This is a tool for convenience. You can always assign directories explicitly to variable with any name you like.\nExample:\n\nFour windows will pop out one by one allowing you to assign directories to variables dir_stat, dir_tsAIN, dir_molchan, dir_jointstation:\ndirselectassign('dir_stat','dir_tsAIN','dir_molchan','dir_jointstation');\n(Read the printed message in the Command Window)\nTotal 7 windows will pop out one by one allowing you to assign directories to the variables with default names dir_stat, dir_tsAIN , dir_molchan, dir_jointstation, dir_data, dir_catalog, dir_toolbox:\ndirselectassign();\n(Read the printed message in the Command Window)\n\n\n\nfft_of_the_day\nFourier transform of the one-day data.\n\n\nfitting_degree_summary\nfitting_degree_summary gives the object for fitting-degree plot.\n\n\nformatForecastingPhase\n[frcphase] = formatForecastingPhase(frcphase,trnphase) is the function for converting the argument that the keyword option â€˜ForecastingPhaseâ€™ takes.\n\n\ngenID\nGenerate trial identifier.\n\n\ngetRcs\nSRc = getRcs(dir_molchan,targetpattern) returns unique Rc as a struct with field names being the station code (stn[â€¦]). Example\ntargetpattern = sprintf('[%s]stn*.mat', get_tags(fmt.InfoFileName_molscore, '', 'once'));\nSRc = getRcs(dir_molchan,targetpattern)\n\n\nloadSheet\nloadSheet(filepath,whatisthis) is deprecated; use checkcatatlog and checkstation instead.\n\n\nmkdir_default\nmkdir_default creates/makes folders by default and return their directories with default variable names. The default structure is:\n                   variable           default folder name\n    â•”â• dir_main â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n    â•‘            â”œâ”€dir_stat         =   'StatisticIndex' â•‘\n    â•‘            â”œâ”€dir_tsAIN        =   'tsAIN'          â•‘\n    â•‘            â”œâ”€dir_molchan      =   'MolchanScore'   â•‘\n    â•‘            â””â”€dir_jointstation =   'JointStation'   â•‘\n    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nExample:\n[dir_stat, dir_tsAIN, dir_molchan, dir_jointstation] =\n  mkdir_default(fullfile(pwd,'output_var'))\n[dir_stat, dir_jointstation] =\n  mkdir_default(fullfile(pwd,'var-output'), 'Directories', {'StatisticIndex'; 'JointStation'})\n\n\nmodeldiscard\nFilter models negatively (modeldiscard)\n\n\nmodelselect\nFilter models positively (modelselect)\n\n\nprpfunctions\nprp_list = prpfunctions() returns the list of existing preprocessing functions that you can apply (those located in the same directory (namely, dir_prp = 'src/preprocess') as the function no). Noted that those under the sub-directories of dir_prp wonâ€™t be listed.\n\n\nrenamecols\nrenamecols(alias, O) rename the column name that matche either in alias of the table O to the newname.\n\n\ntabledragandfill\nA small tool that fill the empty cells of a column by the most recent non-empty value (just like â€˜click, drag, and fillâ€™ in the excel).\nExample: CWBcatalog = tabledragandfill(CWBcatalog, colname1, colname2, ...)"
  }
]